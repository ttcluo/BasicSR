import torch
from torch import nn as nn
from torch.nn import functional as F

from basicsr.utils.registry import ARCH_REGISTRY
from .arch_util import ResidualBlockNoBN, flow_warp, make_layer
from .edvr_arch import PCDAlignment, TSAFusion
from .spynet_arch import SpyNet, SpyNet_bkup
from .spynet_arch import Spy_S_Net
# from .fastflow_arch import fastflow
# from .liteflow2_arch import liteflow2
from .raftnet_arch import RAFT  
from .raftnetS_arch import RAFT_S
from .gmflow_arch import GMFlow
from .gmflow_reducearch import GMFlow_reduce
from .gmflow_reduce02arch import GMFlow_reduce02
from .raftupnet01_arch import Raft_upNet00, Raft_upNet,Raft_upNetx3, Raft_upNetx4, Raft_upNetx4_new, Raft_upNetx4_newflow, Raft_upNetx4_newflow2
from mmcv.ops import ModulatedDeformConv2d, modulated_deform_conv2d
from mmcv.cnn import constant_init
import torch as T
from functools import reduce

@ARCH_REGISTRY.register()
class TT_VSR_FG_TR_SB_x4_top(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        self.spynet = Raft_upNetx4(spynet_path)  #  SpyNet
        # self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(2*num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment(
                    2 * num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()
        # print("[x]",x.shape)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[feat_current 0 ]",feat_current.shape)   #  [4, 64, 128, 128]
            # print("[flow 0 ]",flow.shape)
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1).cuda()
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,3,3,64,64)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        # flows_forward, flows_backward = self.get_flow(x)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w).cuda()
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w).cuda()
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                spa_mask = self.spa_mask(x_mk)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop).cuda()
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :].cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                spa_mask = self.spa_mask(x_mk)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout




@ARCH_REGISTRY.register()
class TT_VSR_FG_TR_SB_x4_top_new(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        # self.spynet = Raft_upNetx4_new(spynet_path)  #  SpyNet
        self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(2*num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment_02(
                    2 * num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=4,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()
        # print("[x]",x.shape)

        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[feat_current 0 ]",feat_current.shape)   #  [4, 64, 128, 128]
            # print("[flow 0 ]",flow.shape)
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1).cuda()
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,3,3,64,64)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        # flows_forward, flows_backward = self.get_flow(x)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w).cuda()
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w).cuda()
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                spa_mask = self.spa_mask(x_mk)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop).cuda()
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :].cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                spa_mask = self.spa_mask(x_mk)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout


@ARCH_REGISTRY.register()
class TT_VSR_FG_TR_SB_x4_top_newflow(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        self.spynet = Raft_upNetx4_newflow(spynet_path)  #  SpyNet
        # self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(2*num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment(
                    2 * num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)
        # self.deform_align = OurDeformableAlignment_02(
        #             2 * num_feat,
        #             num_feat,
        #             3,
        #             padding=1,
        #             deform_groups=4,  #  16
        #             max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()
        # print("[x]",x.shape)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[feat_current 0 ]",feat_current.shape)   #  [4, 64, 128, 128]
            # print("[flow 0 ]",flow.shape)
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1).cuda()
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,3,3,64,64)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        # flows_forward, flows_backward = self.get_flow(x)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w).cuda()
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w).cuda()
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                spa_mask = self.spa_mask(x_mk)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop).cuda()
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :].cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                spa_mask = self.spa_mask(x_mk)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout




@ARCH_REGISTRY.register()
class TT_VSR_FG_TR_SB_x4_top_newflow_2(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        self.spynet = Raft_upNetx4_newflow2(spynet_path)  #  SpyNet
        # self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(2*num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment(
                    2 * num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)
        # self.deform_align = OurDeformableAlignment_02(
        #             2 * num_feat,
        #             num_feat,
        #             3,
        #             padding=1,
        #             deform_groups=4,  #  16
        #             max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()
        # print("[x]",x.shape)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[feat_current 0 ]",feat_current.shape)   #  [4, 64, 128, 128]
            # print("[flow 0 ]",flow.shape)
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1).cuda()
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,3,3,64,64)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        # flows_forward, flows_backward = self.get_flow(x)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w).cuda()
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w).cuda()
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # spa_mask = self.spa_mask(x_mk)
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop).cuda()
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :].cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # spa_mask = self.spa_mask(x_mk)
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout



@ARCH_REGISTRY.register()
class TT_VSR_FG_TR_SB_x4_top_newflow_3(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        # self.spynet = Raft_upNetx4_newflow2(spynet_path)  #  SpyNet
        self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(2*num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        # self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        # self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        # self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        # self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)


        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment(
                    2 * num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)
        # self.deform_align = OurDeformableAlignment_02(
        #             2 * num_feat,
        #             num_feat,
        #             3,
        #             padding=1,
        #             deform_groups=4,  #  16
        #             max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)
        self.pixel_shuffle = nn.PixelShuffle(2)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()
        # print("[x]",x.shape)

        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[feat_current 0 ]",feat_current.shape)   #  [4, 64, 128, 128]
            # print("[flow 0 ]",flow.shape)
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1).cuda()
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,3,3,64,64)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        # x0 = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe
        # print('{x0}',x.shape)

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        # b_flow, n_flow, c_flow, h_flow, w_flow = flows_forward.shape 
        # flows_forward = F.interpolate(flows_forward, size=(c_flow, h_flow//self.scale, w_flow//self.scale), mode='trilinear', align_corners=False)
        # flows_backward = F.interpolate(flows_backward, size=(c_flow, h_flow//self.scale, w_flow//self.scale), mode='trilinear', align_corners=False)

        # flows_forward, flows_backward = self.get_flow(x)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w).cuda()
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w).cuda()
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # spa_mask = self.spa_mask(x_mk)
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop).cuda()
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :].cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # spa_mask = self.spa_mask(x_mk)
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
            # x_i = F.interpolate(x_i, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)


            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout


################################    VSR_FG_TR_SB    ################################################



@ARCH_REGISTRY.register()
class TT_VSR_FG_TR_SB_x4_00(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet Raft_upNet000
        # self.spynet = Raft_upNet000(spynet_path)

        # propagation
        # self.backward_fusion = nn.Conv2d(16*num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)

        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        # self.forward_fusion = nn.Conv2d(16*num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)

        self.forward_trunk = ConvResidualBlocks(3 + num_feat , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(num_feat + num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat* 4 , 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat* 4 , 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last_0 = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.conv_last = nn.Conv2d(num_feat* 4, 3, 3, 1, 1)

        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()  #  OurDeformableAlignment
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            # print("flow ",flow.shape)

            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)  
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feat_current]",feat_current.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[flow]",flow.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        # h_input = h
        # w_input = w
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)  #  False
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)

        # flows_forward, flows_backward = self.get_flow(x)
        # flows_forward = F.interpolate(flows_forward, size=(2, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # flows_backward = F.interpolate(flows_backward, size=(2, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # print("flows_forward",flows_forward.shape)
        # print("flows_backward",flows_backward.shape)
        
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        draft_cube = []
        feat_prop = x.new_zeros(b, self.num_feat, h_input, w_input)
        # flow = flows_backward.new_zeros(b, 2, h, w)
        flow = flows_backward.new_zeros(b, 2, h_input, w_input)

        spa_mask = x.new_zeros(b, 3, h_input, w_input)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # print("flow 1", flow.shape)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # for bb in range(b):
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow) 

                # for ii in range(self.scale):
                #     for jj in range(self.scale):
                #         flow_tmp =  flow[:, :, ii::self.scale, jj::self.scale] / self.scale
                #         draft = self.FlowDeformableAlignment(feat_prop, flow_tmp.contiguous())  #  .view(-1) 
                #         draft_cube.append(draft)
                #         # draft_cube = draft

                # # print("draft_cube 1",len(draft_cube), draft_cube[0].shape)
                # tmp_tensor = torch.cat((draft_cube[0],draft_cube[1],draft_cube[2],draft_cube[3],draft_cube[4],draft_cube[5],draft_cube[6],draft_cube[7],draft_cube[8],draft_cube[9],draft_cube[10],
                #                         draft_cube[11],draft_cube[12],draft_cube[13],draft_cube[14],draft_cube[15]),1 )

                # for iii in range(0,len(draft_cube),2):
                #     tmp_tensor = torch.cat([tmp_tensor, torch.cat(draft_cube[iii],draft_cube[iii+1])])

                # feat_prop = torch.cat([tmp_tensor, x_i], 1)
                # feat_prop = self.backward_fusion(feat_prop)

                # feat_prop = torch.cat([torch.stack(draft_cube),x_i], 1)
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # print("draft_cube",len(draft_cube))
                # feat_prop = torch.cat((torch.cat(draft_cube[:len(draft_cube)//2]),  torch.cat(draft_cube[len(draft_cube)//2:])))
                # feat_prop = reduce(lambda x,y: T.cat((x,y)), draft_cube[:] )
                # print("feat_prop",len(feat_prop))
                # feat_prop = torch.cat((torch.cat(draft_cube[:num+1]),torch.cat(draft_cube[num+1:])))
                # feat_prop = torch.cat(([x_i],draft_cube), 1)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            # print("feat_prop",feat_prop.shape, x_i.shape)
            # feat_prop = torch.cat((x_i), 
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
             
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        # draft_cube = []
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # for bb in b:
                # for ii in range(self.scale):
                #     for jj in range(self.scale):
                #         flow_tmp =  flow[:, :, ii::self.scale, jj::self.scale] / self.scale
                #         draft = self.FlowDeformableAlignment(feat_prop, flow_tmp.contiguous())  #  .view(-1) 
                #         draft_cube.append(draft)
                #         # draft_cube = draft

                # # print("draft_cube 1",len(draft_cube), draft_cube[0].shape)
                # tmp_tensor = torch.cat((draft_cube[0],draft_cube[1],draft_cube[2],draft_cube[3],draft_cube[4],draft_cube[5],draft_cube[6],draft_cube[7],draft_cube[8],draft_cube[9],draft_cube[10],
                #                         draft_cube[11],draft_cube[12],draft_cube[13],draft_cube[14],draft_cube[15]),1 )

                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)
            '''
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            flow_prop = self.flow_trunk(x_temporal)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            spm_prop = self.spa_mask_1(flow_prop)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            spam_prop = torch.cat([x_temporal, spm_prop], dim=1)  #  x_temporal
            spam_prop = self.spam_trunk(spam_prop) 
            feat_prop = torch.cat([x_i, flow_prop, spam_prop ], dim=1)   #  feat_prop
            '''

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  
            feat_prop = torch.cat([x_i, feat_prop], dim=1)   #  feat_prop

            # feat_prop = torch.cat([x_i, out_l[i], flow_prop, feat_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)
            # feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.conv_last_0(out)

            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.conv_last(out)
            # print("out",out.shape)
            # print("x_i",x_i.shape)
            base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
                      
            out_l[i] = out + base # + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        # if self.is_training:
        #     return flows_forward, flows_backward, finout
        # if not self.is_training:
        #     return finout


        return finout



@ARCH_REGISTRY.register()
class TT_VSR_FG_TR_SB_x4_00_new(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None,
                 is_training=True):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True
        self.is_training = is_training

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet Raft_upNet000
        # self.spynet = Raft_upNet000(spynet_path)

        # propagation
        # self.backward_fusion = nn.Conv2d(16*num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)

        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        # self.forward_fusion = nn.Conv2d(16*num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)

        self.forward_trunk = ConvResidualBlocks(3 + num_feat , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(num_feat + num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat* 4 , 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat* 4 , 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last_0 = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.conv_last = nn.Conv2d(num_feat* 4, 3, 3, 1, 1)

        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        self.pixel_shuffle = nn.PixelShuffle(2)
        #  #  OurDeformableAlignment
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            # print("flow ",flow.shape)

            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)  
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feat_current]",feat_current.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[flow]",flow.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        # h_input = h
        # w_input = w
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)  #  False
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)

        # flows_forward, flows_backward = self.get_flow(x)
        # flows_forward = F.interpolate(flows_forward, size=(2, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # flows_backward = F.interpolate(flows_backward, size=(2, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # print("flows_forward",flows_forward.shape)
        # print("flows_backward",flows_backward.shape)
        
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        draft_cube = []
        feat_prop = x.new_zeros(b, self.num_feat, h_input, w_input)
        flow = flows_backward.new_zeros(b, 2, h, w)
        # flow = flows_backward.new_zeros(b, 2, h_input, w_input)

        spa_mask = x.new_zeros(b, 3, h_input, w_input)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # print("flow 1", flow.shape)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # for bb in range(b):
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow) 

                # for ii in range(self.scale):
                #     for jj in range(self.scale):
                #         flow_tmp =  flow[:, :, ii::self.scale, jj::self.scale] / self.scale
                #         draft = self.FlowDeformableAlignment(feat_prop, flow_tmp.contiguous())  #  .view(-1) 
                #         draft_cube.append(draft)
                #         # draft_cube = draft

                # # print("draft_cube 1",len(draft_cube), draft_cube[0].shape)
                # tmp_tensor = torch.cat((draft_cube[0],draft_cube[1],draft_cube[2],draft_cube[3],draft_cube[4],draft_cube[5],draft_cube[6],draft_cube[7],draft_cube[8],draft_cube[9],draft_cube[10],
                #                         draft_cube[11],draft_cube[12],draft_cube[13],draft_cube[14],draft_cube[15]),1 )

                # for iii in range(0,len(draft_cube),2):
                #     tmp_tensor = torch.cat([tmp_tensor, torch.cat(draft_cube[iii],draft_cube[iii+1])])

                # feat_prop = torch.cat([tmp_tensor, x_i], 1)
                # feat_prop = self.backward_fusion(feat_prop)

                # feat_prop = torch.cat([torch.stack(draft_cube),x_i], 1)
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # print("draft_cube",len(draft_cube))
                # feat_prop = torch.cat((torch.cat(draft_cube[:len(draft_cube)//2]),  torch.cat(draft_cube[len(draft_cube)//2:])))
                # feat_prop = reduce(lambda x,y: T.cat((x,y)), draft_cube[:] )
                # print("feat_prop",len(feat_prop))
                # feat_prop = torch.cat((torch.cat(draft_cube[:num+1]),torch.cat(draft_cube[num+1:])))
                # feat_prop = torch.cat(([x_i],draft_cube), 1)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            # print("feat_prop",feat_prop.shape, x_i.shape)
            # feat_prop = torch.cat((x_i), 
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
             
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        # draft_cube = []
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # for bb in b:
                # for ii in range(self.scale):
                #     for jj in range(self.scale):
                #         flow_tmp =  flow[:, :, ii::self.scale, jj::self.scale] / self.scale
                #         draft = self.FlowDeformableAlignment(feat_prop, flow_tmp.contiguous())  #  .view(-1) 
                #         draft_cube.append(draft)
                #         # draft_cube = draft

                # # print("draft_cube 1",len(draft_cube), draft_cube[0].shape)
                # tmp_tensor = torch.cat((draft_cube[0],draft_cube[1],draft_cube[2],draft_cube[3],draft_cube[4],draft_cube[5],draft_cube[6],draft_cube[7],draft_cube[8],draft_cube[9],draft_cube[10],
                #                         draft_cube[11],draft_cube[12],draft_cube[13],draft_cube[14],draft_cube[15]),1 )

                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)
            '''
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            flow_prop = self.flow_trunk(x_temporal)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            spm_prop = self.spa_mask_1(flow_prop)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            spam_prop = torch.cat([x_temporal, spm_prop], dim=1)  #  x_temporal
            spam_prop = self.spam_trunk(spam_prop) 
            feat_prop = torch.cat([x_i, flow_prop, spam_prop ], dim=1)   #  feat_prop
            '''

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  
            feat_prop = torch.cat([x_i, feat_prop], dim=1)   #  feat_prop

            # feat_prop = torch.cat([x_i, out_l[i], flow_prop, feat_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)
            # feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.conv_last_0(out)

            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.conv_last(out)
            # print("out",out.shape)
            # print("x_i",x_i.shape)
            base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
                      
            out_l[i] = out + base # + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        # if self.is_training:
        #     return finout, flows_forward, flows_backward
        # if not self.is_training:
        #     return finout


        return finout


@ARCH_REGISTRY.register()
class TT_VSR_FG_TR_SB_x4_01(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        # self.spynet = Raft_upNetx4(spynet_path)  #  SpyNet
        self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 + 3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3 + num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3+3+num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment(
                    2 * num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1



        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(3 , num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 3, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)
        # print("[x]",x.shape)

        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[feat_current 0 ]",feat_current.shape)   #  [4, 64, 128, 128]
            # print("[flow 0 ]",flow.shape)   #  [4, 64, 128, 128]

            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))  # 
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # print("[x]",x.shape)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("{x}",x.shape)

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        # flows_forward, flows_backward = self.get_flow(x)
        flows_forward = F.interpolate(flows_forward, size=(2, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        flows_backward = F.interpolate(flows_backward, size=(2, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # print("{feat_prop}",feat_prop.shape)  #  [4, 64, 256, 256]
                # print("{flow}",flow.shape)  #  [4, 2, 256, 256]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

           
            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([out_l[i], x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = out_l[i] + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            flow_prop = self.flow_trunk(x_temporal)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            spm_prop = self.spa_mask_1(x_i)  #  x_i
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # spam_prop = torch.cat([x_i, spm_prop], dim=1)  #  x_temporal
            # spam_prop = self.spam_trunk(spam_prop) 

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  
            # feat_prop = torch.cat([x_i, flow_prop, spam_prop ], dim=1)   #  feat_prop

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, flow_prop, spm_prop], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout



class OurDeformableAlignment(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(OurDeformableAlignment, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.conv_offset_2 = nn.Sequential(
            nn.Conv2d(self.out_channels+4 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )


        self.conv_mask = nn.Sequential(
            nn.Conv2d(2*self.out_channels , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 9 * self.deform_groups, 3, 1, 1),
        )

        self.conv_changeto_flow = nn.Sequential(
            nn.Conv2d(self.out_channels//2 + self.out_channels//16 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 2, 3, 1, 1),
        )


        self.conv_bisoff = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 18 * self.deform_groups, 3, 1, 1),
        )

        self.fc = nn.Sequential(
            nn.Linear(144, 144 , bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(144 , 144, bias=False),
            nn.ReLU(inplace=True),
        )
        self.SELayer = SELayer(9 * self.deform_groups)

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # offset = torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))

        # print('[offset]',offset.shape)  # [4, 144, 128, 128]
        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        all_off = torch.cat([extra_feat, x], dim=1)
        # print('[x]',x.shape)
        # print('[all_off]',all_off.shape)
        extra_offset = self.max_residue_magnitude * self.conv_bisoff(all_off)
        
        # print('[offset]',offset.shape)  #  [2, 288, 64, 64]
        # print('[flow_1]',flow_1.shape)  #  [2, 2, 64, 64]
        offset_1 = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  + extra_offset   #   

        offset_1_flow = self.conv_changeto_flow(offset_1)
        # print('[extra_feat]',extra_feat.shape) # 
        # print('[offset_1_flow]',offset_1_flow.shape)
        # print('[flow_1]',flow_1.shape)
        extra_feat_2 = flow_warp(extra_feat, offset_1_flow.permute(0, 2, 3, 1))
        extra_feat_2 = torch.cat([extra_feat_2, flow_1], dim=1)  
        # print('[extra_feat_2]',extra_feat_2.shape)
        out_2 = self.conv_offset_2(extra_feat_2) 
        o1_2, o2_2 , mask_2 = torch.chunk(out_2, 3, dim=1)
        offset_2 = self.max_residue_magnitude * torch.tanh(torch.cat((o1_2, o2_2), dim=1))  
        offset_2 = offset_1 + offset_2 + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset

        # mask   mask 
        # x_feat = self.conv_mask(x)
        # print('[mask]', mask.shape)
        # mask = mask + x_feat
        # mask = torch.cat([extra_feat, flow_1], dim=1) 
        mask = self.SELayer(mask_2)  # + mask_2
        mask = torch.sigmoid(mask)  #  


        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset_2, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT




class OurDeformableAlignment_02(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """
    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(OurDeformableAlignment_02, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.conv_offset_2 = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )


        self.conv_mask = nn.Sequential(
            nn.Conv2d(2*self.out_channels , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 9 * self.deform_groups, 3, 1, 1),
        )

        self.conv_changeto_flow = nn.Sequential(
            nn.Conv2d(2*9 * self.deform_groups , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 2, 3, 1, 1),
        )


        self.conv_bisoff = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 18 * self.deform_groups, 3, 1, 1),
        )

        self.fc = nn.Sequential(
            nn.Linear(144, 144 , bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(144 , 144, bias=False),
            nn.ReLU(inplace=True),
        )
        self.SELayer = SELayer(9 * self.deform_groups)

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        torch.cuda.empty_cache()
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))  

        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        all_off = torch.cat([extra_feat, x], dim=1)
        extra_offset = self.max_residue_magnitude * self.conv_bisoff(all_off)

        offset_1 = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  + extra_offset   #   
        offset_1_flow = self.conv_changeto_flow(offset_1)
        extra_feat_2 = flow_warp(extra_feat, offset_1_flow.permute(0, 2, 3, 1))
        # extra_feat_2 = torch.cat([extra_feat_2, flow_1], dim=1)  
        extra_feat_2 = torch.cat([extra_feat_2, x], dim=1)  
        out_2 = self.conv_offset_2(extra_feat_2) 
        o1_2, o2_2 , mask_2 = torch.chunk(out_2, 3, dim=1)
        offset_2 = self.max_residue_magnitude * torch.tanh(torch.cat((o1_2, o2_2), dim=1))  
        offset_2 = offset_1 + offset_2 + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset

        # mask   mask 
        # x_feat = self.conv_mask(x)
        # print('[mask]', mask.shape)
        # mask = mask + x_feat
        # mask = torch.cat([extra_feat, flow_1], dim=1) 
        mask = self.SELayer(mask_2) # + mask_2
        mask = torch.sigmoid(mask)  #  


        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset_2, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)

        return OUT




class OurDeformableAlignment_03(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(OurDeformableAlignment_03, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.conv_offset_2 = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )


        self.conv_mask = nn.Sequential(
            nn.Conv2d(2*self.out_channels , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 9 * self.deform_groups, 3, 1, 1),
        )

        self.conv_changeto_flow = nn.Sequential(
            nn.Conv2d(2*9 * self.deform_groups , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 2, 3, 1, 1),
        )


        self.conv_bisoff = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 18 * self.deform_groups, 3, 1, 1),
         )

        self.fc = nn.Sequential(
            nn.Linear(144, 144 , bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(144 , 144, bias=False),
            nn.ReLU(inplace=True),
        )
        self.SELayer = SELayer(9 * self.deform_groups)

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # offset = torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))

        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        # all_off = torch.cat([extra_feat, x], dim=1)
        # extra_offset = self.max_residue_magnitude * self.conv_bisoff(all_off)
        
        offset_1 = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset   #   
        print('[offset_1]',offset_1.shape)
        # offset_1_flow = self.conv_changeto_flow(offset_1)
        # extra_feat_2 = flow_warp(extra_feat, offset_1_flow.permute(0, 2, 3, 1))
        extra_feat_2 = torch.cat([extra_feat, x], dim=1)  
        out_2 = self.conv_offset_2(extra_feat_2) 
        out_2 = extra_feat
        o1_2, o2_2 , mask_2 = torch.chunk(out_2, 3, dim=1)
        offset_2 = self.max_residue_magnitude * torch.tanh(torch.cat((o1_2, o2_2), dim=1))  
        print('[offset_2]',offset_2.shape)
        offset_2 = offset_1 + offset_2 + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset
        print('[offset_2 after]',offset_2.shape)
        offset_2 = offset_2.cuda()
        # mask   mask 
        # x_feat = self.conv_mask(x)
        # print('[mask]', mask.shape)
        # mask = mask + x_feat
        # mask = torch.cat([extra_feat, flow_1], dim=1) 
        # mask = self.SELayer(mask)  # + mask_2
        mask = torch.sigmoid(mask).cuda()  #  


        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset_2, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)

        return OUT




class OurCoarseDeformableAlignment_03(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(OurCoarseDeformableAlignment_03, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        # self.conv_offset_2 = nn.Sequential(
        #     nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        # )


        self.conv_mask = nn.Sequential(
            nn.Conv2d(2*self.out_channels , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 9 * self.deform_groups, 3, 1, 1),
        )

        # self.conv_changeto_flow = nn.Sequential(
        #     nn.Conv2d(2*9 * self.deform_groups , self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, 2, 3, 1, 1),
        # )


        self.conv_bisoff = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 18 * self.deform_groups, 3, 1, 1),
        )

        self.fc = nn.Sequential(
            nn.Linear(144, 144 , bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(144 , 144, bias=False),
            nn.ReLU(inplace=True),
        )
        self.SELayer = SELayer(9 * self.deform_groups)

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # offset = torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))

        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        # all_off = torch.cat([extra_feat, x], dim=1)
        # extra_offset = self.max_residue_magnitude * self.conv_bisoff(all_off)
        
        # offset_1 = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset   #   
        # # offset_1_flow = self.conv_changeto_flow(offset_1)
        # # extra_feat_2 = flow_warp(extra_feat, offset_1_flow.permute(0, 2, 3, 1))
        # extra_feat_2 = torch.cat([extra_feat, x], dim=1)  
        # out_2 = self.conv_offset_2(extra_feat_2) 
        # o1_2, o2_2 , mask_2 = torch.chunk(out_2, 3, dim=1)
        # offset_2 = self.max_residue_magnitude * torch.tanh(torch.cat((o1_2, o2_2), dim=1))  
        # offset_2 = offset_1 + offset_2 + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset
        # offset_2 = offset_2.cuda()

        # mask   mask 
        # x_feat = self.conv_mask(x)
        # print('[mask]', mask.shape)
        # mask = mask + x_feat
        # mask = torch.cat([extra_feat, flow_1], dim=1) 
        mask = self.SELayer(mask)  # + mask_2
        mask = torch.sigmoid(mask).cuda()  #  


        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT



class OurRefineDeformableAlignment_03(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(OurRefineDeformableAlignment_03, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        # self.conv_offset_2 = nn.Sequential(
        #     nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        # )


        self.conv_mask = nn.Sequential(
            nn.Conv2d(2*self.out_channels , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 9 * self.deform_groups, 3, 1, 1),
        )

        self.conv_changeto_flow = nn.Sequential(
            nn.Conv2d(2*9 * self.deform_groups , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 2, 3, 1, 1),
        )


        self.conv_bisoff = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 18 * self.deform_groups, 3, 1, 1),
        )

        self.fc = nn.Sequential(
            nn.Linear(144, 144 , bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(144 , 144, bias=False),
            nn.ReLU(inplace=True),
        )
        self.SELayer = SELayer(9 * self.deform_groups)

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # offset = torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))

        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        # all_off = torch.cat([extra_feat, x], dim=1)
        # extra_offset = self.max_residue_magnitude * self.conv_bisoff(all_off)
        
        offset_1 = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset   #   
        # offset_1_flow = self.conv_changeto_flow(offset_1)
        # extra_feat_2 = flow_warp(extra_feat, offset_1_flow.permute(0, 2, 3, 1))
        # extra_feat_2 = torch.cat([extra_feat, x], dim=1)  
        # out_2 = self.conv_offset_2(extra_feat_2) 
        # o1_2, o2_2 , mask_2 = torch.chunk(out_2, 3, dim=1)
        # offset_2 = self.max_residue_magnitude * torch.tanh(torch.cat((o1_2, o2_2), dim=1))  
        offset_2 = offset_1 +  flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset
        offset_2 = offset_2.cuda()
        # mask   mask 
        # x_feat = self.conv_mask(x)
        # print('[mask]', mask.shape)
        # mask = mask + x_feat
        # mask = torch.cat([extra_feat, flow_1], dim=1) 
        mask = self.SELayer(mask)  # + mask_2
        mask = torch.sigmoid(mask).cuda()  #  


        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset_2, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT




class DCNAlignment_03(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(DCNAlignment_03, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.conv_offset_2 = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )


        self.conv_mask = nn.Sequential(
            nn.Conv2d(2*self.out_channels , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 9 * self.deform_groups, 3, 1, 1),
        )

        self.conv_changeto_flow = nn.Sequential(
            nn.Conv2d(2*9 * self.deform_groups , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 2, 3, 1, 1),
        )


        self.conv_bisoff = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 18 * self.deform_groups, 3, 1, 1),
        )

        self.fc = nn.Sequential(
            nn.Linear(144, 144 , bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(144 , 144, bias=False),
            nn.ReLU(inplace=True),
        )
        self.SELayer = SELayer(9 * self.deform_groups)

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        mask = torch.sigmoid(mask)  #  

        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # offset = torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))

        # torch.cuda.empty_cache()
        # torch.cuda.empty_cache()
        # # all_off = torch.cat([extra_feat, x], dim=1)
        # # extra_offset = self.max_residue_magnitude * self.conv_bisoff(all_off)
        
        # offset_1 = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset   #   
        # # offset_1_flow = self.conv_changeto_flow(offset_1)
        # # extra_feat_2 = flow_warp(extra_feat, offset_1_flow.permute(0, 2, 3, 1))
        # extra_feat_2 = torch.cat([extra_feat, x], dim=1)  
        # out_2 = self.conv_offset_2(extra_feat_2) 
        # o1_2, o2_2 , mask_2 = torch.chunk(out_2, 3, dim=1)
        # offset_2 = self.max_residue_magnitude * torch.tanh(torch.cat((o1_2, o2_2), dim=1))  
        # offset_2 = offset_1 + offset_2 + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset

        # # mask   mask 
        # # x_feat = self.conv_mask(x)
        # # print('[mask]', mask.shape)
        # # mask = mask + x_feat
        # # mask = torch.cat([extra_feat, flow_1], dim=1) 
        # mask = self.SELayer(mask)  # + mask_2
        # mask = torch.sigmoid(mask)  #  


        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT








@ARCH_REGISTRY.register()
class BasicVSRx4(nn.Module):
    """A recurrent network for video SR. Now only x4 is supported.
    Args:
        num_feat (int): Number of channels. Default: 64.
        num_block (int): Number of residual blocks for each branch. Default: 15
        spynet_path (str): Path to the pretrained weights of SPyNet. Default: None.
    """

    def __init__(self, num_feat=64, num_block=15, spynet_path=None):
        super().__init__()
        self.num_feat = num_feat

        # alignment
        self.spynet = SpyNet_bkup(spynet_path)

        # propagation
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)
        self.forward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        # reconstruction
        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def forward(self, x):
        """Forward function of BasicVSR.
        Args:
            x: Input frames with shape (b, n, c, h, w). n is the temporal dimension / number of frames.
        """
        flows_forward, flows_backward = self.get_flow(x)
        b, n, _, h, w = x.size()

        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))

            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)
            if i == n //2:
                featuremap_visual(feat_prop, feature_title='basicvsr_alignfeat')


            # upsample
            out = torch.cat([out_l[i], feat_prop], dim=1)
            out = self.lrelu(self.fusion(out))
            out = self.lrelu(self.pixel_shuffle(self.upconv1(out)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)






'''
@ARCH_REGISTRY.register()
class BasicVSRx4(nn.Module):
    """BasicVSR network structure for video super-resolution.
    Support only x4 upsampling.
    Paper:
        BasicVSR: The Search for Essential Components in Video Super-Resolution
        and Beyond, CVPR, 2021
    Args:
        mid_channels (int): Channel number of the intermediate features.
            Default: 64.
        num_blocks (int): Number of residual blocks in each propagation branch.
            Default: 30.
        spynet_pretrained (str): Pre-trained model path of SPyNet.
            Default: None.
    """

    def __init__(self, num_feat=64, num_block=30, spynet_path=None):

        super().__init__()

        self.mid_channels = num_feat
        mid_channels = num_feat

        # optical flow network for feature alignment
        self.spynet = SpyNet_bkup(spynet_path)

        # propagation branches
        self.backward_resblocks = ResidualBlocksWithInputConv(
            mid_channels + 3, mid_channels, num_block)
        self.forward_resblocks = ResidualBlocksWithInputConv(
            mid_channels + 3, mid_channels, num_block)

        # upsample
        self.fusion = nn.Conv2d(
            mid_channels * 2, mid_channels, 1, 1, 0, bias=True)
        self.upsample1 = PixelShufflePack(
            mid_channels, mid_channels, 2, upsample_kernel=3)
        self.upsample2 = PixelShufflePack(
            mid_channels, 64, 2, upsample_kernel=3)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)
        self.img_upsample = nn.Upsample(
            scale_factor=4, mode='bilinear', align_corners=False)

        # activation function
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def check_if_mirror_extended(self, lrs):
        """Check whether the input is a mirror-extended sequence.
        If mirror-extended, the i-th (i=0, ..., t-1) frame is equal to the
        (t-1-i)-th frame.
        Args:
            lrs (tensor): Input LR images with shape (n, t, c, h, w)
        """

        self.is_mirror_extended = False
        if lrs.size(1) % 2 == 0:
            lrs_1, lrs_2 = torch.chunk(lrs, 2, dim=1)
            if torch.norm(lrs_1 - lrs_2.flip(1)) == 0:
                self.is_mirror_extended = True

    def compute_flow(self, lrs):
        """Compute optical flow using SPyNet for feature warping.
        Note that if the input is an mirror-extended sequence, 'flows_forward'
        is not needed, since it is equal to 'flows_backward.flip(1)'.
        Args:
            lrs (tensor): Input LR images with shape (n, t, c, h, w)
        Return:
            tuple(Tensor): Optical flow. 'flows_forward' corresponds to the
                flows used for forward-time propagation (current to previous).
                'flows_backward' corresponds to the flows used for
                backward-time propagation (current to next).
        """

        n, t, c, h, w = lrs.size()
        lrs_1 = lrs[:, :-1, :, :, :].reshape(-1, c, h, w)
        lrs_2 = lrs[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(lrs_1, lrs_2).view(n, t - 1, 2, h, w)

        if self.is_mirror_extended:  # flows_forward = flows_backward.flip(1)
            flows_forward = None
        else:
            flows_forward = self.spynet(lrs_2, lrs_1).view(n, t - 1, 2, h, w)

        return flows_forward, flows_backward

    def forward(self, lrs):
        """Forward function for BasicVSR.
        Args:
            lrs (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Output HR sequence with shape (n, t, c, 4h, 4w).
        """

        n, t, c, h, w = lrs.size()
        assert h >= 64 and w >= 64, (
            'The height and width of inputs should be at least 64, '
            f'but got {h} and {w}.')

        # check whether the input is an extended sequence
        self.check_if_mirror_extended(lrs)

        # compute optical flow
        flows_forward, flows_backward = self.compute_flow(lrs)

        # backward-time propagation
        outputs = []
        feat_prop = lrs.new_zeros(n, self.mid_channels, h, w)
        for i in range(t - 1, -1, -1):
            if i < t - 1:  # no warping required for the last timestep
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))

            feat_prop = torch.cat([lrs[:, i, :, :, :], feat_prop], dim=1)
            feat_prop = self.backward_resblocks(feat_prop)

            outputs.append(feat_prop)
        outputs = outputs[::-1]

        # forward-time propagation and upsampling
        feat_prop = torch.zeros_like(feat_prop)
        for i in range(0, t):
            lr_curr = lrs[:, i, :, :, :]
            if i > 0:  # no warping required for the first timestep
                if flows_forward is not None:
                    flow = flows_forward[:, i - 1, :, :, :]
                else:
                    flow = flows_backward[:, -i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))

            feat_prop = torch.cat([lr_curr, feat_prop], dim=1)
            feat_prop = self.forward_resblocks(feat_prop)

            # upsampling given the backward and forward features
            out = torch.cat([outputs[i], feat_prop], dim=1)
            out = self.lrelu(self.fusion(out))
            out = self.lrelu(self.upsample1(out))
            out = self.lrelu(self.upsample2(out))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = self.img_upsample(lr_curr)
            out += base
            outputs[i] = out

        return torch.stack(outputs, dim=1)

    # def init_weights(self, pretrained=None, strict=True):
    #     """Init weights for models.
    #     Args:
    #         pretrained (str, optional): Path for pretrained weights. If given
    #             None, pretrained weights will not be loaded. Defaults: None.
    #         strict (boo, optional): Whether strictly load the pretrained model.
    #             Defaults to True.
    #     """
    #     # if isinstance(pretrained, str):
    #     #     logger = get_root_logger()
    #     #     load_checkpoint(self, pretrained, strict=strict, logger=logger)
    #     # elif pretrained is not None:
    #     #     raise TypeError(f'"pretrained" must be a str or None. '
    #     #                     f'But received {type(pretrained)}.')



class PixelShufflePack(nn.Module):
    """Pixel Shuffle upsample layer.
    Args:
        in_channels (int): Number of input channels.
        out_channels (int): Number of output channels.
        scale_factor (int): Upsample ratio.
        upsample_kernel (int): Kernel size of Conv layer to expand channels.
    Returns:
        Upsampled feature map.
    """

    def __init__(self, in_channels, out_channels, scale_factor,
                 upsample_kernel):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.scale_factor = scale_factor
        self.upsample_kernel = upsample_kernel
        self.upsample_conv = nn.Conv2d(
            self.in_channels,
            self.out_channels * scale_factor * scale_factor,
            self.upsample_kernel,
            padding=(self.upsample_kernel - 1) // 2)
        # self.init_weights()

    # def init_weights(self):
    #     """Initialize weights for PixelShufflePack."""
    #     default_init_weights(self, 1)

    def forward(self, x):
        """Forward function for PixelShufflePack.
        Args:
            x (Tensor): Input tensor with shape (n, c, h, w).
        Returns:
            Tensor: Forward results.
        """
        x = self.upsample_conv(x)
        x = F.pixel_shuffle(x, self.scale_factor)
        return x




class ResidualBlocksWithInputConv(nn.Module):
    """Residual blocks with a convolution in front.
    Args:
        in_channels (int): Number of input channels of the first conv.
        out_channels (int): Number of channels of the residual blocks.
            Default: 64.
        num_blocks (int): Number of residual blocks. Default: 30.
    """

    def __init__(self, in_channels, out_channels=64, num_blocks=30):
        super().__init__()

        main = []

        # a convolution used to match the channels of the residual blocks
        main.append(nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=True))
        main.append(nn.LeakyReLU(negative_slope=0.1, inplace=True))

        # residual blocks
        main.append(
            make_layer(
                ResidualBlockNoBN, num_blocks, mid_channels=out_channels))

        self.main = nn.Sequential(*main)

    def forward(self, feat):
        """Forward function for ResidualBlocksWithInputConv.
        Args:
            feat (Tensor): Input feature with shape (n, in_channels, h, w)
        Returns:
            Tensor: Output feature with shape (n, out_channels, h, w)
        """
        return self.main(feat)




class ResidualBlockNoBN(nn.Module):
    """Residual block without BN.
    It has a style of:
    ::
        ---Conv-ReLU-Conv-+-
         |________________|
    Args:
        mid_channels (int): Channel number of intermediate features.
            Default: 64.
        res_scale (float): Used to scale the residual before addition.
            Default: 1.0.
    """

    def __init__(self, mid_channels=64, res_scale=1.0):
        super().__init__()
        self.res_scale = res_scale
        self.conv1 = nn.Conv2d(mid_channels, mid_channels, 3, 1, 1, bias=True)
        self.conv2 = nn.Conv2d(mid_channels, mid_channels, 3, 1, 1, bias=True)

        self.relu = nn.ReLU(inplace=True)

        # if res_scale < 1.0, use the default initialization, as in EDSR.
        # if res_scale = 1.0, use scaled kaiming_init, as in MSRResNet.
        # if res_scale == 1.0:
        #     self.init_weights()

    # def init_weights(self):
    #     """Initialize weights for ResidualBlockNoBN.
    #     Initialization methods like `kaiming_init` are for VGG-style modules.
    #     For modules with residual paths, using smaller std is better for
    #     stability and performance. We empirically use 0.1. See more details in
    #     "ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks"
    #     """

    #     for m in [self.conv1, self.conv2]:
    #         default_init_weights(m, 0.1)

    def forward(self, x):
        """Forward function.
        Args:
            x (Tensor): Input tensor with shape (n, c, h, w).
        Returns:
            Tensor: Forward results.
        """

        identity = x
        out = self.conv2(self.relu(self.conv1(x)))
        return identity + out * self.res_scale



def default_init_weights(module, scale=1):
    """Initialize network weights.
    Args:
        modules (nn.Module): Modules to be initialized.
        scale (float): Scale initialized weights, especially for residual
            blocks.
    """
    for m in module.modules():
        if isinstance(m, nn.Conv2d):
            torch.nn.init.kaiming_normal_(m, a=0, mode='fan_in')
            m.weight.data *= scale
        elif isinstance(m, nn.Linear):
            torch.nn.init.kaiming_normal_(m, a=0, mode='fan_in')
            m.weight.data *= scale
        # elif isinstance(m, _BatchNorm):
        #     constant_init(m.weight, val=1, bias=0)


def make_layer(block, num_blocks, **kwarg):
    """Make layers by stacking the same blocks.
    Args:
        block (nn.module): nn.module class for basic block.
        num_blocks (int): number of blocks.
    Returns:
        nn.Sequential: Stacked blocks in nn.Sequential.
    """
    layers = []
    for _ in range(num_blocks):
        layers.append(block(**kwarg))
    return nn.Sequential(*layers)

'''


@ARCH_REGISTRY.register()
class BasicVSRx3(nn.Module):
    """A recurrent network for video SR. Now only x4 is supported.

    Args:
        num_feat (int): Number of channels. Default: 64.
        num_block (int): Number of residual blocks for each branch. Default: 15
        spynet_path (str): Path to the pretrained weights of SPyNet. Default: None.
    """

    def __init__(self, num_feat=64, num_block=15, spynet_path=None):
        super().__init__()
        self.num_feat = num_feat

        # alignment
        self.spynet = SpyNet_bkup(spynet_path)

        # propagation
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)
        self.forward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        # reconstruction
        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)
        self.upconv1 = nn.Conv2d(num_feat, 64 * 9, 3, 1, 1, bias=True)
        # self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(3)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def forward(self, x):
        flows_forward, flows_backward = self.get_flow(x)
        b, n, _, h, w = x.size()

        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))

            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = torch.cat([out_l[i], feat_prop], dim=1)
            out = self.lrelu(self.fusion(out))
            out = self.lrelu(self.pixel_shuffle(self.upconv1(out)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=3, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)








@ARCH_REGISTRY.register()
class BasicVSRx2(nn.Module):
    """A recurrent network for video SR. Now only x4 is supported.

    Args:
        num_feat (int): Number of channels. Default: 64.
        num_block (int): Number of residual blocks for each branch. Default: 15
        spynet_path (str): Path to the pretrained weights of SPyNet. Default: None.
    """

    def __init__(self, num_feat=64, num_block=15, spynet_path=None):
        super().__init__()
        self.num_feat = num_feat

        # alignment
        self.spynet = SpyNet_bkup(spynet_path)

        # propagation
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)
        self.forward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        # reconstruction
        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 2, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(32, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def forward(self, x):
        flows_forward, flows_backward = self.get_flow(x)
        b, n, _, h, w = x.size()

        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))

            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = torch.cat([out_l[i], feat_prop], dim=1)
            out = self.lrelu(self.fusion(out))
            out = self.lrelu(self.pixel_shuffle(self.upconv1(out)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)


class ConvResidualBlocks(nn.Module):

    def __init__(self, num_in_ch=3, num_out_ch=64, num_block=15):
        super().__init__()
        self.main = nn.Sequential(
            nn.Conv2d(num_in_ch, num_out_ch, 3, 1, 1, bias=True), nn.LeakyReLU(negative_slope=0.1, inplace=True),
            make_layer(ResidualBlockNoBN, num_block, num_feat=num_out_ch))

    def forward(self, fea):
        return self.main(fea)


@ARCH_REGISTRY.register()
class IconVSRx4(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet_bkup(spynet_path)

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def forward(self, x):
        b, n, _, h_input, w_input = x.size()

        x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]


@ARCH_REGISTRY.register()
class IconVSRx4_alignment(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)
        self.is_with_alignment = True

        self.deform_align = SecondOrderDeformableAlignment(
                    2*self.num_feat,
                    self.num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)


        self.pixel_shuffle = nn.PixelShuffle(2)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    
    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w).cuda()
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats.cuda()
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[feat_current 0 ]",feat_current.shape)   #  [4, 64, 128, 128]
            # print("[flow 0 ]",flow.shape)   #  [4, 64, 128, 128]

            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))  # 
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feafeat_propts]",feat_prop.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[flow]",flow.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow).cuda()   # feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop
    
    
    
    
    def forward(self, x):
        b, n, _, h_input, w_input = x.size()

        x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)
        
        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :].cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow).cuda()
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :].cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow).cuda()
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]



@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_RAFT(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        # self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.RAFT(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.RAFT(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout



############################################     X2       ########################################################



@ARCH_REGISTRY.register()
class ICMEVSRx2_FG_SPM_Spynet_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout





@ARCH_REGISTRY.register()
class ICMEVSRx2_FG_SPM_Spynet_S_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout







############################################     X3       ########################################################


@ARCH_REGISTRY.register()
class IconVSRx3(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet_bkup(spynet_path)

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, 64 * 9, 3, 1, 1, bias=True)
        # self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(3)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def forward(self, x):
        b, n, _, h_input, w_input = x.size()

        x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=3, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :3 * h_input, :3 * w_input]









@ARCH_REGISTRY.register()
class ICMEVSRx3_FG_SPM_Spynet_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 3
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*9, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(3)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=3, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :3 * h_input, :3 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout






@ARCH_REGISTRY.register()
class ICMEVSRx3_FG_SPM_Spynet_S_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 3
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*9, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(3)
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=3, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :3 * h_input, :3 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout







@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_Spynet(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout




import matplotlib.pylab as plt



@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_Spynet_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                if i == n//2:
                    featuremap_visual(feat_prop, feature_title='Forward_alignfeat')
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                if i == n//2:
                    featuremap_visual(feat_prop, feature_title='Backward_alignfeat')
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)
            featuremap_visual(x_back, feature_title='TRBfor_feat')

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            featuremap_visual(x_back, feature_title='TRBback_feat')
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)
            featuremap_visual(x_back, feature_title='SEB_feat')

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout







@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_Spynet_img_warp_our(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    # def get_keyframe_feature(self, x, keyframe_idx):
    #     if self.temporal_padding == 2:
    #         x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
    #     elif self.temporal_padding == 3:
    #         x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
    #     x = torch.cat(x, dim=1)

    #     num_frames = 2 * self.temporal_padding + 1
    #     feats_keyframe = {}
    #     for i in keyframe_idx:
    #         # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
    #         feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
    #     return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout


# S [1]


import numpy as np

def featuremap_visual(feature, iter = 1,  out_dir=None,  # 
                    save_feature=True,  # 
                    feature_title=None,  # shapetitle
                    num_ch=-1,  # -1 or None 
                    nrow=8,  # 
                    padding=0,  # 
                    pad_value=1  # 
                    ):
    # feature = feature.detach().cpu()
    b, c, h, w = feature.shape
    feature = feature[0][31:32,:,:]   #  30:31
    # feature = feature.unsqueeze(1)
    
    img = feature.detach().cpu()
    img = img.numpy()   #  .squeeze(1)
    # print('[img]',img.shape)
    images = img.transpose((1, 2, 0))

    # title = str(images.shape) if feature_title is None else str(feature_title)
    title = str(h) + '-' + str(w) + '-' + str(c) + '-' + feature_title + '-'  +  str(iter) 

    plt.title(title)
    min_val = np.amin(images)
    max_val = np.amax(images)    
    images =  (images - min_val)/(max_val-min_val)
    # images = images/ 255.
    
    out_root = '/share3/home/zqiang/BasicSR0906/viz_feat/' + title + '.png' 
    # print('[out_root]',out_root)
    plt.figure()
    plt.imshow(images)
    plt.axis('off')
    fig = plt.gcf()
    # fig.set_size_inches(7.0/3,7.0/3) #dpi = 300, output = 700*700 pixels
    plt.gca().xaxis.set_major_locator(plt.NullLocator())
    plt.gca().yaxis.set_major_locator(plt.NullLocator())
    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)
    plt.margins(0,0)
    plt.savefig(out_root, cmap='cmap',bbox_inches='tight', transparent=True, dpi=100)  #  , pad_inches = 0







@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_Spynet_S_img_warp_our(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w).cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w).cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,1,3,180,320)
        print('[x]',x.shape)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x) # .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                if i == n //2:
                    featuremap_visual(feat_prop, feature_title='forward_alignfeat')
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                if i == n //2:
                    featuremap_visual(feat_prop, feature_title='backward_alignfeat')
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)

            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            featuremap_visual(x_back, feature_title='TRB_backfeat')
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            featuremap_visual(x_temporal, feature_title='TRB_combfeat')
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)
            featuremap_visual(feat_prop, feature_title='SEB_combfeat')

            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout







@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_fastflow_img_warp_our(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = fastflow(spynet_path)  #  SpyNet  fastflow 
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    # def get_keyframe_feature(self, x, keyframe_idx):
    #     if self.temporal_padding == 2:
    #         x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
    #     elif self.temporal_padding == 3:
    #         x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
    #     x = torch.cat(x, dim=1)

    #     num_frames = 2 * self.temporal_padding + 1
    #     feats_keyframe = {}
    #     for i in keyframe_idx:
    #         # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
    #         feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
    #     return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout







@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_liteflow2_img_warp_our(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = liteflow2(spynet_path)  #  SpyNet  fastflow 
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()
        

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()
        # print('[x_1 shape]',x_1.shape)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w).cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w).cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    # def get_keyframe_feature(self, x, keyframe_idx):
    #     if self.temporal_padding == 2:
    #         x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
    #     elif self.temporal_padding == 3:
    #         x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
    #     x = torch.cat(x, dim=1)

    #     num_frames = 2 * self.temporal_padding + 1
    #     feats_keyframe = {}
    #     for i in keyframe_idx:
    #         # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
    #         feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
    #     return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout







@ARCH_REGISTRY.register()
class ICMEVSRx4_warp_SPM_Spynet_img_warp_our(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        # self.deform_align = OurDeformableAlignment_03(
        #             2*num_feat,
        #             num_feat,
        #             3,
        #             padding=1,
        #             deform_groups=16,  #  16
        #             max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    # def get_keyframe_feature(self, x, keyframe_idx):
    #     if self.temporal_padding == 2:
    #         x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
    #     elif self.temporal_padding == 3:
    #         x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
    #     x = torch.cat(x, dim=1)

    #     num_frames = 2 * self.temporal_padding + 1
    #     feats_keyframe = {}
    #     for i in keyframe_idx:
    #         # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
    #         feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
    #     return feats_keyframe

    # def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

    #     nf, _, hf, wf = feats.shape
    #     n, t, h, w = flow.shape

    #     feat_prop = flow.new_zeros(n, self.num_feat, h, w)
    #     # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
    #     feat_current = feats
    #     feat_current = feat_current.cuda()
    #     feat_prop = feat_prop.cuda()
    #     flow = flow.cuda()
    #     # print("cuda feat_current",feat_current.device)

    #     # second-order deformable alignment
    #     if self.is_with_alignment:
    #         # print("feat_prop feat_current",feat_prop.shape)
    #         flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
    #         flow_n1 = flow_n1.cuda()
    #         # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
    #         torch.cuda.empty_cache()
    #         cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
    #         cond = cond.cuda()
    #         # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

    #         # flow-guided deformable convolution
    #         cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
    #         cond = cond.cuda()
    #         cond = self.conv_trans(cond)

    #         feat_prop = torch.cat([feat_prop, feats], dim=1)
    #         # feat_prop = self.conv_fetr(feat_prop)
    #         # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
    #         # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
    #         # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
    #         torch.cuda.empty_cache()
    #         feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
    #         feat_prop = feat_prop.cuda()
    #         torch.cuda.empty_cache()
    #         # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

    #     return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout








@ARCH_REGISTRY.register()
class ICMEVSRx4_DCN_SPM_Spynet_img_warp_our(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        # self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        # self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = DCNAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        # self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        # hid_conv_lst = []
        # for _ in range(8 - 2):
        #     hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        # self.hid_conv = nn.Sequential(*hid_conv_lst)
        # self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    # def get_keyframe_feature(self, x, keyframe_idx):
    #     if self.temporal_padding == 2:
    #         x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
    #     elif self.temporal_padding == 3:
    #         x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
    #     x = torch.cat(x, dim=1)

    #     num_frames = 2 * self.temporal_padding + 1
    #     feats_keyframe = {}
    #     for i in keyframe_idx:
    #         # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
    #         feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
    #     return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout



@ARCH_REGISTRY.register()
class ICMEVSRx4_DCN_SPM_Spynet_S_img_warp_our(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        # self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        # self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = DCNAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        # self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        # hid_conv_lst = []
        # for _ in range(8 - 2):
        #     hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        # self.hid_conv = nn.Sequential(*hid_conv_lst)
        # self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    # def get_keyframe_feature(self, x, keyframe_idx):
    #     if self.temporal_padding == 2:
    #         x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
    #     elif self.temporal_padding == 3:
    #         x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
    #     x = torch.cat(x, dim=1)

    #     num_frames = 2 * self.temporal_padding + 1
    #     feats_keyframe = {}
    #     for i in keyframe_idx:
    #         # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
    #         feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
    #     return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout






@ARCH_REGISTRY.register()
class ICMEVSRx4_warponly_Spynet(nn.Module):

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3+num_feat , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        # modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
        #                 nn.ReLU(True),
        #                 nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        # self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)
# 
    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    # def gumbel_softmax(self, x, dim, tau):
    #     gumbels = torch.rand_like(x)
    #     while bool((gumbels == 0).sum() > 0):
    #         gumbels = torch.rand_like(x)

    #     gumbels = -(-gumbels.log()).log()
    #     gumbels = (x + gumbels) / tau
    #     x = gumbels.softmax(dim)

    #     return x
    
    

    # def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

    #     nf, _, hf, wf = feats.shape
    #     n, t, h, w = flow.shape

    #     feat_prop = flow.new_zeros(n, self.num_feat, h, w)
    #     # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
    #     feat_current = feats
    #     feat_current = feat_current.cuda()
    #     feat_prop = feat_prop.cuda()
    #     flow = flow.cuda()
    #     # print("cuda feat_current",feat_current.device)

    #     # second-order deformable alignment
    #     if self.is_with_alignment:
    #         # print("feat_prop feat_current",feat_prop.shape)
    #         flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
    #         flow_n1 = flow_n1.cuda()
    #         # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
    #         torch.cuda.empty_cache()
    #         cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
    #         cond = cond.cuda()
    #         # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

    #         # flow-guided deformable convolution
    #         cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
    #         cond = cond.cuda()
    #         cond = self.conv_trans(cond)

    #         feat_prop = torch.cat([feat_prop, feats], dim=1)
    #         # feat_prop = self.conv_fetr(feat_prop)
    #         # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
    #         # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
    #         # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
    #         torch.cuda.empty_cache()
    #         feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
    #         feat_prop = feat_prop.cuda()
    #         torch.cuda.empty_cache()
    #         # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

    #     return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # x_i_1 = x[:, i+1, :, :, :].cuda() 
                # warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
                feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
                feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                # if i < n:
                #     x_i_1 = x[:, i-1, :, :, :].cuda() 
                #     warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # else:
                #     warped_image = torch.zeros_like(x_i).cuda()
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
                feat_prop = self.forward_trunk(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout



# S [2]


@ARCH_REGISTRY.register()
class ICMEVSRx4_warponly_Spynet_S(nn.Module):

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3+num_feat , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)   #  SecondOrderDeformableAlignment_02
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        # modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
        #                 nn.ReLU(True),
        #                 nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        # self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)
# 
    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    # def gumbel_softmax(self, x, dim, tau):
    #     gumbels = torch.rand_like(x)
    #     while bool((gumbels == 0).sum() > 0):
    #         gumbels = torch.rand_like(x)

    #     gumbels = -(-gumbels.log()).log()
    #     gumbels = (x + gumbels) / tau
    #     x = gumbels.softmax(dim)

    #     return x
    
    

    # def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

    #     nf, _, hf, wf = feats.shape
    #     n, t, h, w = flow.shape

    #     feat_prop = flow.new_zeros(n, self.num_feat, h, w)
    #     # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
    #     feat_current = feats
    #     feat_current = feat_current.cuda()
    #     feat_prop = feat_prop.cuda()
    #     flow = flow.cuda()
    #     # print("cuda feat_current",feat_current.device)

    #     # second-order deformable alignment
    #     if self.is_with_alignment:
    #         # print("feat_prop feat_current",feat_prop.shape)
    #         flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
    #         flow_n1 = flow_n1.cuda()
    #         # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
    #         torch.cuda.empty_cache()
    #         cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
    #         cond = cond.cuda()
    #         # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

    #         # flow-guided deformable convolution
    #         cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
    #         cond = cond.cuda()
    #         cond = self.conv_trans(cond)

    #         feat_prop = torch.cat([feat_prop, feats], dim=1)
    #         # feat_prop = self.conv_fetr(feat_prop)
    #         # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
    #         # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
    #         # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
    #         torch.cuda.empty_cache()
    #         feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
    #         feat_prop = feat_prop.cuda()
    #         torch.cuda.empty_cache()
    #         # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

    #     return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # x_i_1 = x[:, i+1, :, :, :].cuda() 
                # warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
                feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
                feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                # if i < n:
                #     x_i_1 = x[:, i-1, :, :, :].cuda() 
                #     warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # else:
                #     warped_image = torch.zeros_like(x_i).cuda()
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
                feat_prop = self.forward_trunk(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout






@ARCH_REGISTRY.register()
class ICMEVSRx4_onlyFG_Spynet(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):

        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)

            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)

            # feat_prop = self.forward_trunk(feat_prop)
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout


# S [3]


@ARCH_REGISTRY.register()
class ICMEVSRx4_onlyFG_Spynet_S(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)   #  SecondOrderDeformableAlignment_02
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):

        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)

            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)

            # feat_prop = self.forward_trunk(feat_prop)
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout





@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_TRB_Spynet_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)  #  SecondOrderDeformableAlignment_02
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x


    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            feat_prop = torch.cat([x_i, out_l[i], feat_prop, x_temporal ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout



# S [4]


@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_TRB_Spynet_S_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet Spy_S_Net  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x


    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            feat_prop = torch.cat([x_i, out_l[i], feat_prop, x_temporal ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout

















@ARCH_REGISTRY.register()
class ICMEVSRx4_coarseFG_TRB_Spynet_S_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurCoarseDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x


    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            feat_prop = torch.cat([x_i, out_l[i], feat_prop, x_temporal ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout






@ARCH_REGISTRY.register()
class ICMEVSRx4_refineFG_TRB_Spynet_S_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = OurRefineDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x


    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            feat_prop = torch.cat([x_i, out_l[i], feat_prop, x_temporal ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout















@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SSB_Spynet_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        # self.spynet = nn.DataParallel(SpyNet(spynet_path))
        # USE_CUDA = torch.cuda.is_available()
        # device = torch.device("cuda:0" if USE_CUDA else "cpu")
        # self.spynet.to(device)

        # self.spynet = SpyNet(spynet_path)  #  SpyNet  
        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  

        # self.spynet = self.spynet.module
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x


    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(feat_prop)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout


# S [5]

@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SSB_Spynet_S_img_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride  
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        # self.spynet = nn.DataParallel(SpyNet(spynet_path))
        # USE_CUDA = torch.cuda.is_available()
        # device = torch.device("cuda:0" if USE_CUDA else "cpu")
        # self.spynet.to(device)

        self.spynet = Spy_S_Net(spynet_path)  #  SpyNet  
        # self.spynet = self.spynet.module
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat+3, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)  #  OurDeformableAlignment_03
        self.deform_align = OurDeformableAlignment_03(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x


    def FlowDeformableAlignment(self, feats, flow ,x_i, warped_image):

        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1, warped_image], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda() 

            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                x_i_1 = x[:, i+1, :, :, :].cuda() 
                warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                if i < n:
                    x_i_1 = x[:, i-1, :, :, :].cuda() 
                    warped_image = flow_warp(x_i_1, flow.permute(0, 2, 3, 1))
                else:
                    warped_image = torch.zeros_like(x_i).cuda()
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i, warped_image)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(feat_prop)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout





@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_RAFT_small(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        # self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        self.RAFT = RAFT_S(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.RAFT(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.RAFT(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout









@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_RAFT_small(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        # self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet000
        self.RAFT = RAFT_S(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        # self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        # self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        # hid_conv_lst = []
        # for _ in range(8 - 2):
        #     hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        # self.hid_conv = nn.Sequential(*hid_conv_lst)
        # self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        # modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
        #                 nn.ReLU(True),
        #                 nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        # self.head = nn.Sequential(*modules_head)

        # spatial mask
        # self.spa_mask = nn.Sequential(
        #     nn.Conv2d(3, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.AvgPool2d(2),
        #     nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        # )
        # self.tau = 1

        # self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        # self.spa_mask = nn.Sequential(
        #     nn.Conv2d(3, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.AvgPool2d(2),
        #     nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        # )
        # self.tau = 1

        # self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        # self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        # modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
        #                 nn.ReLU(True),
        #                 nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        # self.head = nn.Sequential(*modules_head)
        # self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        # self.spa_mask = nn.Sequential(
        #     nn.Conv2d(3, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.AvgPool2d(2),
        #     nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        # )
        # self.spa_mask_1 = nn.Sequential(
        #     nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.AvgPool2d(2),
        #     nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        # )
        # self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.RAFT(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.RAFT(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout










@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_SPM_gmflow(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = GMFlow(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout






@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_gmflowreduce(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = GMFlow_reduce(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        # self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        # self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        # self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        # self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        # hid_conv_lst = []
        # for _ in range(8 - 2):
        #     hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        # self.hid_conv = nn.Sequential(*hid_conv_lst)
        # self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        # modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
        #                 nn.ReLU(True),
        #                 nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        # self.head = nn.Sequential(*modules_head)

        # spatial mask
        # self.spa_mask = nn.Sequential(
        #     nn.Conv2d(3, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.AvgPool2d(2),
        #     nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        # )
        # self.tau = 1

        # self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        # self.spa_mask = nn.Sequential(
        #     nn.Conv2d(3, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.AvgPool2d(2),
        #     nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        # )
        # self.tau = 1

        # self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        # self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        # modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
        #                 nn.ReLU(True),
        #                 nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        # self.head = nn.Sequential(*modules_head)
        # self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout


class ESA(nn.Module):
    def __init__(self, n_feats, conv):
        super(ESA, self).__init__()
        f = n_feats // 4
        self.conv1 = conv(n_feats, f, kernel_size=1)
        self.conv_f = conv(f, f, kernel_size=1)
        self.conv_max = conv(f, f, kernel_size=3, padding=1)
        self.conv2 = conv(f, f, kernel_size=3, stride=2, padding=0)
        self.conv3 = conv(f, f, kernel_size=3, padding=1)
        self.conv3_ = conv(f, f, kernel_size=3, padding=1)
        self.conv4 = conv(f, n_feats, kernel_size=1)
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        c1_ = (self.conv1(x))
        c1 = self.conv2(c1_)
        v_max = F.max_pool2d(c1, kernel_size=7, stride=3)
        v_range = self.relu(self.conv_max(v_max))
        c3 = self.relu(self.conv3(v_range))
        c3 = self.conv3_(c3)
        c3 = F.interpolate(c3, (x.size(2), x.size(3)), mode='bilinear', align_corners=False) 
        cf = self.conv_f(c1_)
        c4 = self.conv4(c3+cf)
        m = self.sigmoid(c4)

        return x * m

class EDBB(nn.Module):
    def __init__(self, inp_planes, out_planes, depth_multiplier=None, act_type='prelu', with_idt = False, deploy=False, with_13=False, gv=False):
        super(EDBB, self).__init__()
        
        self.deploy = deploy
        self.act_type = act_type
        
        self.inp_planes = inp_planes
        self.out_planes = out_planes

        self.gv = gv          

        if depth_multiplier is None:
            self.depth_multiplier = inp_planes
        else: 
            self.depth_multiplier = depth_multiplier   # For mobilenet, it is better to have 2X internal channels
        
        if deploy:
            self.rep_conv = nn.Conv2d(in_channels=inp_planes, out_channels=out_planes, kernel_size=3, stride=1,
                                      padding=1, bias=True)
        else: 
            self.with_13 = with_13
            if with_idt and (self.inp_planes == self.out_planes):
                self.with_idt = True
            else:
                self.with_idt = False

            self.rep_conv = nn.Conv2d(self.inp_planes, self.out_planes, kernel_size=3, padding=1)
            self.conv1x1 = nn.Conv2d(self.inp_planes, self.out_planes, kernel_size=1, padding=0)
            self.conv1x1_3x3 = SeqConv3x3('conv1x1-conv3x3', self.inp_planes, self.out_planes, self.depth_multiplier)
            self.conv1x1_sbx = SeqConv3x3('conv1x1-sobelx', self.inp_planes, self.out_planes, -1)
            self.conv1x1_sby = SeqConv3x3('conv1x1-sobely', self.inp_planes, self.out_planes, -1)
            self.conv1x1_lpl = SeqConv3x3('conv1x1-laplacian', self.inp_planes, self.out_planes, -1)

        if self.act_type == 'prelu':
            self.act = nn.PReLU(num_parameters=self.out_planes)
        elif self.act_type == 'relu':
            self.act = nn.ReLU(inplace=True)
        elif self.act_type == 'rrelu':
            self.act = nn.RReLU(lower=-0.05, upper=0.05)
        elif self.act_type == 'softplus':
            self.act = nn.Softplus()
        elif self.act_type == 'linear':
            pass
        else:
            raise ValueError('The type of activation if not support!')

    def forward(self, x):
        if self.deploy:
            y = self.rep_conv(x)
        elif self.gv:
            y = self.rep_conv(x)     + \
                self.conv1x1_sbx(x) + \
                self.conv1x1_sby(x) + \
                self.conv1x1_lpl(x) + x 
        else:
            y = self.rep_conv(x)     + \
                self.conv1x1(x)     + \
                self.conv1x1_sbx(x) + \
                self.conv1x1_sby(x) + \
                self.conv1x1_lpl(x)            
                #self.conv1x1_3x3(x) + \
            if self.with_idt:
                y += x
            if self.with_13:
                y += self.conv1x1_3x3(x)

        if self.act_type != 'linear':
            y = self.act(y)
        return y
    
    def switch_to_gv(self):
        if self.gv:
            return
        self.gv = True
        
        K0, B0 = self.rep_conv.weight, self.rep_conv.bias
        K1, B1 = self.conv1x1_3x3.rep_params()
        K5, B5 = multiscale(self.conv1x1.weight,3), self.conv1x1.bias
        RK, RB = (K0+K5), (B0+B5) 
        if self.with_13:
            RK, RB = RK + K1, RB + B1

        self.rep_conv.weight.data = RK
        self.rep_conv.bias.data = RB
        
        for para in self.parameters():
            para.detach_()
      
    
    def switch_to_deploy(self):

        if self.deploy:
            return
        self.deploy = True
        
        K0, B0 = self.rep_conv.weight, self.rep_conv.bias
        K1, B1 = self.conv1x1_3x3.rep_params()
        K2, B2 = self.conv1x1_sbx.rep_params()
        K3, B3 = self.conv1x1_sby.rep_params()
        K4, B4 = self.conv1x1_lpl.rep_params()
        K5, B5 = multiscale(self.conv1x1.weight,3), self.conv1x1.bias
        if self.gv:
            RK, RB = (K0+K2+K3+K4), (B0+B2+B3+B4) 
        else:
            RK, RB = (K0+K2+K3+K4+K5), (B0+B2+B3+B4+B5) 
            if self.with_13:
                RK, RB = RK + K1, RB + B1
        if self.with_idt:
            device = RK.get_device()
            if device < 0:
                device = None
            K_idt = torch.zeros(self.out_planes, self.out_planes, 3, 3, device=device)
            for i in range(self.out_planes):
                K_idt[i, i, 1, 1] = 1.0
            B_idt = 0.0
            RK, RB = RK + K_idt, RB + B_idt        
            

        self.rep_conv = nn.Conv2d(in_channels=self.inp_planes, out_channels=self.out_planes, kernel_size=3, stride=1,
                                      padding=1, bias=True)
        self.rep_conv.weight.data = RK
        self.rep_conv.bias.data = RB
        
        for para in self.parameters():
            para.detach_()
            
        #self.__delattr__('conv3x3')
        self.__delattr__('conv1x1_3x3')
        self.__delattr__('conv1x1')
        self.__delattr__('conv1x1_sbx')
        self.__delattr__('conv1x1_sby')
        self.__delattr__('conv1x1_lpl')

class EFDB(nn.Module):
    def __init__(self, n_feats=48, dynamic = True, deploy = False, L= None, with_13=False):
        super(EFDB, self).__init__()
        
        self.conv1 = nn.Conv2d(n_feats, n_feats, 1, 1, 0) 
        self.conv2 = EDBB(n_feats,n_feats)
        self.conv3 = EDBB(n_feats,n_feats)

        self.fuse = nn.Conv2d(n_feats*2, n_feats, 1, 1, 0)

        self.att = ESA(n_feats, nn.Conv2d) #MAB(n_feats)# ENLCA(n_feats)  #CoordAtt(n_feats,n_feats,10)# 

        self.branch = nn.ModuleList([nn.Conv2d(n_feats, n_feats//2, 1, 1, 0) for _ in range(4)])

    def forward(self, x):
        out1 = self.conv1(x)
        out2 = self.conv2(out1)
        out3 = self.conv3(out2)

        # fuse [x, out1, out2, out3]
        out = self.fuse(torch.cat([self.branch[0](x), self.branch[1](out1), self.branch[2](out2), self.branch[3](out3)], dim=1))
        out = self.att(out)
        out += x

        return out

def multiscale(kernel, target_kernel_size):
    H_pixels_to_pad = (target_kernel_size - kernel.size(2)) // 2
    W_pixels_to_pad = (target_kernel_size - kernel.size(3)) // 2
    return F.pad(kernel, [H_pixels_to_pad, H_pixels_to_pad, W_pixels_to_pad, W_pixels_to_pad])

class SeqConv3x3(nn.Module):
    def __init__(self, seq_type, inp_planes, out_planes, depth_multiplier):
        super(SeqConv3x3, self).__init__()

        self.type = seq_type
        self.inp_planes = inp_planes
        self.out_planes = out_planes

        if self.type == 'conv1x1-conv3x3':
            self.mid_planes = int(out_planes * depth_multiplier)
            conv0 = torch.nn.Conv2d(self.inp_planes, self.mid_planes, kernel_size=1, padding=0)
            self.k0 = conv0.weight
            self.b0 = conv0.bias

            conv1 = torch.nn.Conv2d(self.mid_planes, self.out_planes, kernel_size=3)
            self.k1 = conv1.weight
            self.b1 = conv1.bias
            
        elif self.type == 'conv1x1-sobelx':
            conv0 = torch.nn.Conv2d(self.inp_planes, self.out_planes, kernel_size=1, padding=0)
            self.k0 = conv0.weight
            self.b0 = conv0.bias

            # init scale & bias
            scale = torch.randn(size=(self.out_planes, 1, 1, 1)) * 1e-3
            self.scale = nn.Parameter(scale)
            # bias = 0.0
            # bias = [bias for c in range(self.out_planes)]
            # bias = torch.FloatTensor(bias)
            bias = torch.randn(self.out_planes) * 1e-3
            bias = torch.reshape(bias, (self.out_planes,))
            self.bias = nn.Parameter(bias)
            # init mask
            self.mask = torch.zeros((self.out_planes, 1, 3, 3), dtype=torch.float32)
            for i in range(self.out_planes):
                self.mask[i, 0, 0, 0] = 1.0
                self.mask[i, 0, 1, 0] = 2.0
                self.mask[i, 0, 2, 0] = 1.0
                self.mask[i, 0, 0, 2] = -1.0
                self.mask[i, 0, 1, 2] = -2.0
                self.mask[i, 0, 2, 2] = -1.0
            self.mask = nn.Parameter(data=self.mask, requires_grad=False)

        elif self.type == 'conv1x1-sobely':
            conv0 = torch.nn.Conv2d(self.inp_planes, self.out_planes, kernel_size=1, padding=0)
            self.k0 = conv0.weight
            self.b0 = conv0.bias

            # init scale & bias
            scale = torch.randn(size=(self.out_planes, 1, 1, 1)) * 1e-3
            self.scale = nn.Parameter(torch.FloatTensor(scale))
            # bias = 0.0
            # bias = [bias for c in range(self.out_planes)]
            # bias = torch.FloatTensor(bias)
            bias = torch.randn(self.out_planes) * 1e-3
            bias = torch.reshape(bias, (self.out_planes,))
            self.bias = nn.Parameter(torch.FloatTensor(bias))
            # init mask
            self.mask = torch.zeros((self.out_planes, 1, 3, 3), dtype=torch.float32)
            for i in range(self.out_planes):
                self.mask[i, 0, 0, 0] = 1.0
                self.mask[i, 0, 0, 1] = 2.0
                self.mask[i, 0, 0, 2] = 1.0
                self.mask[i, 0, 2, 0] = -1.0
                self.mask[i, 0, 2, 1] = -2.0
                self.mask[i, 0, 2, 2] = -1.0
            self.mask = nn.Parameter(data=self.mask, requires_grad=False)

        elif self.type == 'conv1x1-laplacian':
            conv0 = torch.nn.Conv2d(self.inp_planes, self.out_planes, kernel_size=1, padding=0)
            self.k0 = conv0.weight
            self.b0 = conv0.bias

            # init scale & bias
            scale = torch.randn(size=(self.out_planes, 1, 1, 1)) * 1e-3
            self.scale = nn.Parameter(torch.FloatTensor(scale))
            # bias = 0.0
            # bias = [bias for c in range(self.out_planes)]
            # bias = torch.FloatTensor(bias)
            bias = torch.randn(self.out_planes) * 1e-3
            bias = torch.reshape(bias, (self.out_planes,))
            self.bias = nn.Parameter(torch.FloatTensor(bias))
            # init mask
            self.mask = torch.zeros((self.out_planes, 1, 3, 3), dtype=torch.float32)
            for i in range(self.out_planes):
                self.mask[i, 0, 0, 1] = 1.0
                self.mask[i, 0, 1, 0] = 1.0
                self.mask[i, 0, 1, 2] = 1.0
                self.mask[i, 0, 2, 1] = 1.0
                self.mask[i, 0, 1, 1] = -4.0
            self.mask = nn.Parameter(data=self.mask, requires_grad=False)
        else:
            raise ValueError('the type of seqconv is not supported!')

    def forward(self, x):
        if self.type == 'conv1x1-conv3x3':
            # conv-1x1
            y0 = F.conv2d(input=x, weight=self.k0, bias=self.b0, stride=1)
            # explicitly padding with bias
            y0 = F.pad(y0, (1, 1, 1, 1), 'constant', 0)
            b0_pad = self.b0.view(1, -1, 1, 1)
            y0[:, :, 0:1, :] = b0_pad
            y0[:, :, -1:, :] = b0_pad
            y0[:, :, :, 0:1] = b0_pad
            y0[:, :, :, -1:] = b0_pad
            # conv-3x3
            y1 = F.conv2d(input=y0, weight=self.k1, bias=self.b1, stride=1)
        else:
            y0 = F.conv2d(input=x, weight=self.k0, bias=self.b0, stride=1)
            # explicitly padding with bias
            y0 = F.pad(y0, (1, 1, 1, 1), 'constant', 0)
            b0_pad = self.b0.view(1, -1, 1, 1)
            y0[:, :, 0:1, :] = b0_pad
            y0[:, :, -1:, :] = b0_pad
            y0[:, :, :, 0:1] = b0_pad
            y0[:, :, :, -1:] = b0_pad
            # conv-3x3
            y1 = F.conv2d(input=y0, weight=self.scale * self.mask, bias=self.bias, stride=1, groups=self.out_planes)
        return y1
    
    def rep_params(self):
        device = self.k0.get_device()
        if device < 0:
            device = None

        if self.type == 'conv1x1-conv3x3':
            # re-param conv kernel
            RK = F.conv2d(input=self.k1, weight=self.k0.permute(1, 0, 2, 3))
            # re-param conv bias
            RB = torch.ones(1, self.mid_planes, 3, 3, device=device) * self.b0.view(1, -1, 1, 1)
            RB = F.conv2d(input=RB, weight=self.k1).view(-1,) + self.b1
        else:
            tmp = self.scale * self.mask
            k1 = torch.zeros((self.out_planes, self.out_planes, 3, 3), device=device)
            for i in range(self.out_planes):
                k1[i, i, :, :] = tmp[i, 0, :, :]
            b1 = self.bias
            # re-param conv kernel
            RK = F.conv2d(input=k1, weight=self.k0.permute(1, 0, 2, 3))
            # re-param conv bias
            RB = torch.ones(1, self.out_planes, 3, 3, device=device) * self.b0.view(1, -1, 1, 1)
            RB = F.conv2d(input=RB, weight=k1).view(-1,) + b1
        return RK, RB



@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_EFDB_gmflowreduce(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        self.spynet = GMFlow_reduce(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)
        self.EFDB = EFDB(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


           
  
            feat_prop = self.EFDB(feat_prop)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout





@ARCH_REGISTRY.register()
class ICMEVSRx4_CasFG_EFDB_gmflowreduce(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # alignment
        self.spynet = GMFlow_reduce(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = CasDeformableAlignment(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=16,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)
        self.EFDB = EFDB(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()

            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
           
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)      
  
            feat_prop = self.EFDB(feat_prop)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout








@ARCH_REGISTRY.register()
class ICMEVSRx4_FG_gmflowreduce02(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = GMFlow_reduce02(spynet_path)  #  SpyNet  Raft_upNet000
        # self.RAFT = RAFT(spynet_path)  #  SpyNet  Raft_upNet000


        # propagation
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        # self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        # self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+ 2*num_feat , num_feat, num_block)

        # reconstruction
        # self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat*4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_02(
                    2*num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=8,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        # self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        # hid_conv_lst = []
        # for _ in range(8 - 2):
        #     hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        # self.hid_conv = nn.Sequential(*hid_conv_lst)
        # self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        # modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
        #                 nn.ReLU(True),
        #                 nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        # self.head = nn.Sequential(*modules_head)

        # spatial mask
        # self.spa_mask = nn.Sequential(
        #     nn.Conv2d(3, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.AvgPool2d(2),
        #     nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        # )
        # self.tau = 1

        # self.fusion = nn.Conv2d(num_feat * 2, num_feat, 1, 1, 0, bias=True)


        # spatial mask
        # self.spa_mask = nn.Sequential(
        #     nn.Conv2d(3, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.AvgPool2d(2),
        #     nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
        #     nn.ReLU(True),
        #     nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        # )
        # self.tau = 1

        # self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        # self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        # modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
        #                 nn.ReLU(True),
        #                 nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        # self.head = nn.Sequential(*modules_head)
        # self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w).cuda()
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w).cuda()

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)#.cuda()
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)#.cuda()

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow ,x_i):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, self.num_feat, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("[x]",x.shape)

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)# .cuda()
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w).cuda()
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :].cuda()
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1).cuda()
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop).cuda()
        flow = torch.zeros_like(flow).cuda()
        spa_mask = torch.zeros_like(spa_mask).cuda()
        for i in range(0, n):
            x_i = x[:, i, :, :, :].cuda()
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow, x_i)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w).cuda()  # self.head(x.view(-1, c, h, w))
                # # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            # print("[out_sm[i]]",out_sm[i].shape)
            # print("[spa_mask]",spa_mask.shape)


            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1).cuda()
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1).cuda()  #  spam_prop, 
            # feat_prop = self.forward_trunk(feat_prop)

            # # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # # print("[out 1 ]",out.shape)  #  2, 64, 128, 128
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # # print("[out 2 ]",out.shape)  # 2, 64, 256, 256
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)
            # # print("[out 3 ]",out.shape)  #  2, 3, 256, 256
  
            # base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)


            # x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            # x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            # x_back = self.conv_origal(x_i) + x_diff 
            # # x_back = self.flow_trunk(x_back)

            # x_diff = self.FFP_conv(x_back - feat_prop)
            # x_combine = torch.cat([x_back, x_diff], dim=1)
            # x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            # x_temporal = x_back + x_diff 
            # spm_prop = self.spa_mask_1(x_temporal)
            # spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            # out = self.conv_last(out)


            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            x_i = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
           
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # finout = torch.stack(out_l, dim=1)
        # print("[finout]",finout.shape)
        return finout









################################    X2   ################################################



@ARCH_REGISTRY.register()
class IconVSRx2(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet_bkup(spynet_path)

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def forward(self, x):
        b, n, _, h_input, w_input = x.size()

        x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]




@ARCH_REGISTRY.register()
class IconVSRx2_k0(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.Backward_warp = Backward_warp()

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)


    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
   

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()

        x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)

        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.Backward_warp(feat_prop, flow)  # .permute(0, 2, 3, 1)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_sm.insert(0, spa_mask)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        spa_mask = torch.zeros_like(spa_mask)

        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.Backward_warp(feat_prop, flow)  # .permute(0, 2, 3, 1)

            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]



@ARCH_REGISTRY.register()
class IconVSRx2_k0_sw(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.Backward_warp = Backward_warp()

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)


    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
   

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()

        x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)

        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.Backward_warp(feat_prop, flow)  # .permute(0, 2, 3, 1)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_sm.insert(0, spa_mask)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        spa_mask = torch.zeros_like(spa_mask)

        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.Backward_warp(feat_prop, flow)  # .permute(0, 2, 3, 1)

            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]



@ARCH_REGISTRY.register()
class IconVSRx2_k0_sw_refine(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)

        # propagation
        self.backward_fusion = nn.Conv2d(3 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(3 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(4 * num_feat + 3, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)
        self.flow_trunk = ConvResidualBlocks(4, 2, num_block)
        self.flow_fusion = nn.Sequential(
                nn.ConvTranspose2d(2 * num_feat, num_feat, kernel_size=3, stride=1, padding=1, bias=True),
                nn.ReLU(inplace = True))


        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.Backward_warp = Backward_warp()

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
   

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()

        x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_sm = []
        out_fw = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)

        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.Backward_warp(feat_prop, flow)  # .permute(0, 2, 3, 1)
                
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,spa_mask, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_sm.insert(0, spa_mask)
            out_fw.insert(0, flow)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        spa_mask = torch.zeros_like(spa_mask)
        flow = torch.zeros_like(flow)

        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.Backward_warp(feat_prop, flow)  # .permute(0, 2, 3, 1)

            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,spa_mask, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            flow_prop_back = out_fw[i] + flow   #  forewardbackwardflow  warp
            # flow_prop_forw = flow - out_fw[i]
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            featfl_prop = flow_warp(feat_prop, flow_prop_back.permute(0, 2, 3, 1))

            # flow_prop = torch.cat([out_fw[i], -flow], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # featfl_prop = flow_warp(feat_prop, flow_prop.permute(0, 2, 3, 1))

            flow_prop = torch.cat([out_l[i],featfl_prop], dim=1)  # 4 + 64
            flow_prop = self.flow_fusion(flow_prop)
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]





@ARCH_REGISTRY.register()
class IconVSRx2_k0_sw_fg(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.Backward_warp = Backward_warp()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)


    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
   

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe


    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop


    def forward(self, x):
        b, n, _, h_input, w_input = x.size()

        x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)

        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.Backward_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)

            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_sm.insert(0, spa_mask)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        spa_mask = torch.zeros_like(spa_mask)

        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.Backward_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)

            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            # feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
            out += base
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]



@ARCH_REGISTRY.register()
class IconVSRx2_00(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        # reconstruction
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        # print("{x1}",x.shape)
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # print("{x2}",x.shape)

        # x = self.pad_spatial(x)
        h, w = x.shape[3:]

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)

        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            # base = F.interpolate(x_i, scale_factor=2, mode='bilinear', align_corners=False)
            out += x_i
            out_l[i] = out

        return torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]



@ARCH_REGISTRY.register()
class IconVSRx2_warp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        # self.num_frame = num_frame

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(4, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.Backward_warp = Backward_warp()

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

  
    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)
        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # print("[flow]",flow.shape)  #  ([4, 2, 128, 128])
                # feat_prop = self.Backward_warp(feat_prop, flow)  # 
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # print("[spa_mask 2]",spa_mask.shape)    #  [28, 3, 128, 128])
                # print("{feats_keyframe[i]}",feats_keyframe[i].shape)   #  [4, 64, 128, 128]
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                # feat_prop = self.Backward_warp(feat_prop, flow)   #  .permute(0, 2, 3, 1)
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_prop = torch.cat([out_fw[i], -flow], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)


            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout



@ARCH_REGISTRY.register()
class IconVSRx2_FS(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        # self.num_frame = num_frame

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(4, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

  
    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        # print("{x1}",x.shape)
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # print("{x2}",x.shape)

        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        # x_mk = x.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
        # print("[x_mk]",x_mk.shape)   # ([28, 64, 128, 128])
        # spa_mask = self.spa_mask(x_mk)
        # # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
        # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
        # # print("[spa_mask 2]",spa_mask.shape)    #  [28, 3, 128, 128])
        # spa_mask = spa_mask.view(b, n, -1, h, w)
        
        # x = x.view(b, n, -1, h, w)
        # print("[x]",x)
        # att_feat = x * spa_mask  # self.CSAM_module(x, spa_mask)
        # print("[att_feat]",att_feat)
        # att_feat = att_feat
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)
        # print("{feats_keyframe}",len(feats_keyframe))  #  7

        # print("{feats_keyframe}",feats_keyframe[0].shape)   #  ([4, 64, 128, 128])

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # print("[flow]",flow.shape)  #  ([4, 2, 128, 128])
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # print(spa_mask[:,0,:,:]==spa_mask[:,1,:,:])
                # print("[spa_mask 2]",spa_mask.shape)    #  [28, 3, 128, 128])
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # print("{feats_keyframe[i]}",feats_keyframe[i].shape)   #  [4, 64, 128, 128]
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_prop = torch.cat([out_fw[i], -flow], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)


            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out+ x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]
            #  torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout


@ARCH_REGISTRY.register()
class IconVSRx2_FS_01(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        # self.num_frame = num_frame

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(4, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

  
    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        # print("{x1}",x.shape)
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # print("{x2}",x.shape)

        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        
        
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # print("{feats_keyframe}",feats_keyframe[0].shape)   #  ([4, 64, 128, 128])

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # print("[flow]",flow.shape)  #  ([4, 2, 128, 128])
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # print("[spa_mask 2]",spa_mask.shape)    #  [28, 3, 128, 128])
                # print("{feats_keyframe[i]}",feats_keyframe[i].shape)   #  [4, 64, 128, 128]
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_prop = torch.cat([out_fw[i], -flow], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)


            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout


@ARCH_REGISTRY.register()
class IconVSRx2_FS_fg(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(4, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 64, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_prop = torch.cat([out_fw[i], -flow], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout



@ARCH_REGISTRY.register()
class IconVSRx2_FS_fg_01(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 64, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout



@ARCH_REGISTRY.register()
class IconVSRx2_FG_FB_SPM(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # print("[spa_mask before]",spa_mask.shape)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # print("[spa_mask]",spa_mask.shape)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)
            
            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout





@ARCH_REGISTRY.register()
class IconVSRx2_FG_FB_SPM_rp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, num_feat, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        out_l_fore = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        out_l_fore.insert(0, feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)
            
            if i == n-1:
                back_prop = torch.zeros_like(feat_prop) # self.conv_err(x_i)
            else:
                back_prop = out_l[i+1]
            flow_backprop = flow_warp(self.conv_last(back_prop), out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(self.conv_last(out_l_fore[-1]), flow.permute(0, 2, 3, 1))
            out_l_fore.append(feat_prop)
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout




@ARCH_REGISTRY.register()
class IconVSRx2_FG_FB_SPM_secondProp(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, num_feat, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        out_l_fore = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        out_l_fore.insert(0, feat_prop)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)
            
            if i == n-1:
                back_prop = torch.zeros_like(feat_prop) # self.conv_err(x_i)
            else:
                back_prop = out_l[i+1]

            if i >= n-2:
                back_prop2nd = torch.zeros_like(feat_prop) # self.conv_err(x_i)
            else:
                back_prop2nd = out_l[i+2]
            flow_backprop = flow_warp(self.conv_last(back_prop), out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(self.conv_last(out_l_fore[-1]), flow.permute(0, 2, 3, 1))

            flow_backprop2nd = flow_warp(self.conv_last(back_prop2nd), (out_fw[i-1]+out_fw[i]).permute(0, 2, 3, 1))
            flow_foreprop2nd = flow_warp(self.conv_last(out_l_fore[-2]), (flows_forward[:, i - 2, :, :, :]+flow).permute(0, 2, 3, 1))

            out_l_fore.append(feat_prop)
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout




@ARCH_REGISTRY.register()
class IconVSRx2_warp_FB_SPM(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 64, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout



@ARCH_REGISTRY.register()
class IconVSRx2_FS_fg_02(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * num_feat + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 64, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            # print("[i]",i)
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop1 = self.FlowDeformableAlignment(feat_prop, flow)
            if i >= n - 1:
                feat_prop1 = feat_prop
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # print("[ui]",i)
                feat_prop1 = torch.cat([feat_prop1,  feats_keyframe[i]], dim=1)
                feat_prop1 = self.backward_fusion(feat_prop1)
           
            feat_prop1 = torch.cat([x_i, feat_prop1], dim=1)
            feat_prop1 = self.backward_trunk(feat_prop1)
            out_l.insert(0, feat_prop1)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop2 = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i == 0:
                feat_prop2 = feat_prop
            
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop2 = torch.cat([feat_prop2,  feats_keyframe[i]], dim=1)
                feat_prop2 = self.forward_fusion(feat_prop2)
            

            flow_backprop = flow_warp(feat_prop, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop2], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout



@ARCH_REGISTRY.register()
class IconVSRx2_FS_fg_03(nn.Module):  
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """
    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(3 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(3 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(4, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 128, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        self.deform_align = SecondOrderDeformableAlignment01(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.
        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()
        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4
        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')
        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()
        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)
        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop, spa_mask, feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,spa_mask, feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_prop = torch.cat([out_fw[i], -flow], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout



@ARCH_REGISTRY.register()
class IconVSRx2_wokf_FG_FB_SPM(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(2*3+ 3, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 64, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 3, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])
            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
            x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
            spa_mask = self.spa_mask(x_mk)
            spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
            x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
            spa_mask = self.spa_mask(x_mk)
            spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # print("[spam_prop]",spam_prop.shape)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout





@ARCH_REGISTRY.register()
class IconVSRx2_wokf_FG_SPM(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat  + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(2*num_feat+ 3, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 64, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])
            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
            x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
            spa_mask = self.spa_mask(x_mk)
            spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                # feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
            x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
            spa_mask = self.spa_mask(x_mk)
            spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)

            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # print("[spam_prop]",spam_prop.shape)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout






@ARCH_REGISTRY.register()
class IconVSRx2_FG_FB(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 64, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout




@ARCH_REGISTRY.register()
class IconVSRx2_FG_SPM(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(192, 64, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(128, 64, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, 64, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, 64 * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    64,
                    64,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, 64, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(64, 64, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(64, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout





@ARCH_REGISTRY.register()
class IconVSRx2_FG_FB_SPM_01(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout





@ARCH_REGISTRY.register()
class IconVSRx2_FG_wokf(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout







@ARCH_REGISTRY.register()
class IconVSRx2_FG(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNet(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :2 * h_input, :2 * w_input]

        return finout




'''



################################################################################################


@ARCH_REGISTRY.register()
class IconVSRx4_FG_FB_SPM_org(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 2
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet  Raft_upNet00

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat//4, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.pixel_shuffle = nn.PixelShuffle(2)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            # print("[feat_current 0 ]",feat_current.shape) 
            # print("[flow 0 ]",flow.shape) 
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))  # .permute(0, 2, 3, 1)
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        # x0 = x
        # x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # h, w = h_input, w_input

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat,h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            
            out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            out = self.conv_last(out)
            base = F.interpolate(x_i, scale_factor=4, mode='bilinear', align_corners=False)
            # print("{x_i]",x_i.shape)
            # print("{out]",out.shape)
            # print("{base]",base.shape)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + base
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout







################################    X3    ################################################


@ARCH_REGISTRY.register()
class IconVSRx3_FG_FB_SPM(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 3
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = Raft_upNetx3(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3+3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, 3, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        # keyframe_idx = list(range(0, n, self.keyframe_stride))
        # if keyframe_idx[-1] != n - 1:
        #     keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
            x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
            # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
            spa_mask = self.spa_mask(x_mk)
            # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
            spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
            x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
            # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
            spa_mask = self.spa_mask(x_mk)
            # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
            spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                # feat_prop = self.forward_fusion(feat_prop)

            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(feat_prop)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :3 * h_input, :3 * w_input]
        # print("[finout]",finout.shape)
        return finout




################################    X4    ################################################


@ARCH_REGISTRY.register()
class IconVSRx4_FG_FB_SPM(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        self.spynet = Raft_upNetx4(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)
        # print("[x]",x.shape)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # print("[flows_backward]",flows_backward.shape)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout





@ARCH_REGISTRY.register()
class IconVSRx4_FG_FB_SPM_samply(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        self.spynet = Raft_upNetx4(spynet_path)  #  SpyNet

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3+2 * num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(num_feat+num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment01(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)
        # print("[x]",x.shape)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # print("[flows_backward]",flows_backward.shape)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # print("[x]",x.shape)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("{x}",x.shape)

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat//2, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # print("{feat_prop}",feat_prop.shape)  #  [4, 64, 256, 256]
                # print("{flow}",flow.shape)  #  [4, 2, 256, 256]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # print("[finout]",finout.shape)
        finout = finout
        # print("[finout]",finout.shape)

        return finout




@ARCH_REGISTRY.register()
class IconVSRx4_FG_FB_SPM_samply02(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        # self.spynet = Raft_upNetx4(spynet_path)  #  SpyNet
        self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3 + 2*num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment01(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)
        # print("[x]",x.shape)

        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # print("[x]",x.shape)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("{x}",x.shape)

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        # flows_forward, flows_backward = self.get_flow(x0)
        flows_forward, flows_backward = self.get_flow(x)

        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # print("{feat_prop}",feat_prop.shape)  #  [4, 64, 256, 256]
                # print("{flow}",flow.shape)  #  [4, 2, 256, 256]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # print("[finout]",finout.shape)
        finout = finout
        # print("[finout]",finout.shape)

        return finout







@ARCH_REGISTRY.register()
class IconVSRx4_FG_FB_SPM_samply02_00(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        # self.spynet = Raft_upNetx4(spynet_path)  #  SpyNet
        self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 + 3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3 + num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_01(
                    2 * num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(3 , num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 3, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)
        # print("[x]",x.shape)

        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # print("[x]",x.shape)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("{x}",x.shape)

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        # flows_forward, flows_backward = self.get_flow(x0)
        flows_forward, flows_backward = self.get_flow(x)

        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # print("{feat_prop}",feat_prop.shape)  #  [4, 64, 256, 256]
                # print("{flow}",flow.shape)  #  [4, 2, 256, 256]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            # feat_prop = self.forward_trunk(feat_prop)


            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([out_l[i], x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = out_l[i] + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            flow_prop = self.flow_trunk(x_temporal)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            spm_prop = self.spa_mask_1(x_i)  #  x_i
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # spam_prop = torch.cat([x_i, spm_prop], dim=1)  #  x_temporal
            # spam_prop = self.spam_trunk(spam_prop) 

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  
            # feat_prop = torch.cat([x_i, flow_prop, spam_prop ], dim=1)   #  feat_prop

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, flow_prop, spm_prop], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)
            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout











@ARCH_REGISTRY.register()
class IconVSRx4_FG_FB_SPM_samply03(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        # self.spynet = Raft_upNetx4(spynet_path)  #  SpyNet
        self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( 2*num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 + 3, num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(2 * 3 + 3, 3, num_block)
        self.spam_trunk = ConvResidualBlocks(3 + 2*3, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment01(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 3, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)
        # print("[x]",x.shape)

        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # print("[x]",x.shape)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 
        # print("{x}",x.shape)

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        # flows_forward, flows_backward = self.get_flow(x0)
        flows_forward, flows_backward = self.get_flow(x)

        feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                # print("{feat_prop}",feat_prop.shape)  #  [4, 64, 256, 256]
                # print("{flow}",flow.shape)  #  [4, 2, 256, 256]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1]",spa_mask.shape)   #  [28, 3, 128, 128])
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            feat_prop = self.forward_trunk(feat_prop)

            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            # out_res = self.in_conv(out)
            # out_res = self.hid_conv(out_res)
            # residual_out = self.out_conv(out_res)
            # # print("[residual_out new3]",residual_out.shape)   #  ([2, 128, 128, 128])

            # #(2) residual fusion  
            # # residual leaning
            # err = x_i - out #  + down_res
            # out_err = self.lrelu(self.conv_err(err))
            # out_err = out_err + residual_out
            # resid_out = self.conv_err(out_err) #  + x_i  # self.lrelu

            # out = out + x_i + resid_out
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]
        # print("[finout]",finout.shape)
        finout = finout
        # print("[finout]",finout.shape)

        return finout










@ARCH_REGISTRY.register()
class IconVSRx4_FG_FB_SPM_samply04_00(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # self.backward_fusion = nn.Conv2d(2 * num_feat, num_feat, 3, 1, 1, bias=True)
        # alignment
        self.spynet = Raft_upNetx4(spynet_path)  #  SpyNet
        # self.spynet = SpyNet(spynet_path) 

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d( num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(3 * num_feat + 3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(2*num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        # self.pixel_shuffle = nn.PixelShuffle(2)
        self.deform_align = SecondOrderDeformableAlignment_01(
                    2 * num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)
        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)



    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)
        # print("[x]",x.shape)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, self.scale*h, self.scale*w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, self.scale*h, self.scale*w)
        # flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        # flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])

            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[feat_current 0 ]",feat_current.shape)   #  [4, 64, 128, 128]
            # print("[flow 0 ]",flow.shape)
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            # print("[cond]",cond.shape)
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_prop, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        # x = x.reshape(1,7,3,224,224)
        b, n, c, h_input, w_input = x.size()
        x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x0)
        # flows_forward, flows_backward = self.get_flow(x)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, self.num_feat, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                spa_mask = self.spa_mask(x_mk)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            # if i in keyframe_idx:
                x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                spa_mask = self.spa_mask(x_mk)
                spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)

            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            
            # flow_prop = torch.cat([x_i, flow_backprop, flow_foreprop], dim=1)
            # flow_prop = self.flow_trunk(flow_prop)  #  joint optical flow fore - back
            # # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  #  joint spa_mask  fore - back

            # feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            # feat_prop = self.forward_trunk(feat_prop)



            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            # flow_prop = self.flow_trunk(x_temporal)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            spm_prop = self.spa_mask_1(x_temporal)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            # spam_prop = torch.cat([x_temporal, spm_prop], dim=1)  #  x_temporal
            # spam_prop = self.spam_trunk(spam_prop) 

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  
            # feat_prop = torch.cat([x_i, flow_prop, spam_prop ], dim=1)   #  feat_prop

            feat_prop = torch.cat([x_i, out_l[i], feat_prop, spm_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)




            # upsample
            out = self.lrelu(self.upconv1(feat_prop))
            # out = self.lrelu(self.conv_hr(out))
            out = self.conv_last(out)

            
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]

        return finout



'''



class SELayer(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)







class eca_layer(nn.Module):
    """Constructs a ECA module.
    Args:
        channel: Number of channels of the input feature map
        k_size: Adaptive selection of kernel size
    """
    def __init__(self, channel, k_size=3):
        super(eca_layer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False) 
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # feature descriptor on the global spatial information
        y = self.avg_pool(x)

        # Two different branches of ECA module
        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)

        # Multi-scale information fusion
        y = self.sigmoid(y)

        return x * y.expand_as(x)







@ARCH_REGISTRY.register()
class IconVSRx4_FG_FB_SPM_samply04(nn.Module):
    """IconVSR, proposed also in the BasicVSR paper  IconVSRx2_FS_fg
    """

    def __init__(self,
                 num_feat=64,
                 num_block=15,
                 keyframe_stride=5,
                 temporal_padding=2,
                 spynet_path=None,
                 edvr_path=None):
        super().__init__()

        self.num_feat = num_feat
        self.temporal_padding = temporal_padding
        self.keyframe_stride = keyframe_stride
        self.scale = 4
        self.is_with_alignment = True

        # keyframe_branch
        # self.edvr = EDVRFeatureExtractor(temporal_padding * 2 + 1, num_feat, edvr_path)
        # alignment
        self.spynet = SpyNet(spynet_path)  #  SpyNet Raft_upNet000
        # self.spynet = Raft_upNet000(spynet_path)

        # propagation
        self.backward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.backward_trunk = ConvResidualBlocks(num_feat + 3, num_feat, num_block)

        self.forward_fusion = nn.Conv2d(num_feat, num_feat, 3, 1, 1, bias=True)
        self.forward_trunk = ConvResidualBlocks(2 * num_feat +3 , num_feat, num_block)

        self.flow_trunk = ConvResidualBlocks(num_feat, num_feat, num_block)
        self.spam_trunk = ConvResidualBlocks(3 + num_feat, num_feat, num_block)

        # reconstruction
        self.conv_err = nn.Conv2d(3, 3, 3, 1, 1)
        self.conv_trans = nn.Conv2d(3*num_feat, num_feat, 3, 1, 1)
        self.conv_fetr = nn.Conv2d(2*num_feat, num_feat, 3, 1, 1)
        self.upconv1 = nn.Conv2d(num_feat, num_feat , 3, 1, 1, bias=True)
        self.upconv2 = nn.Conv2d(num_feat, num_feat * 4, 3, 1, 1, bias=True)
        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_last = nn.Conv2d(num_feat, 3, 3, 1, 1)

        self.conv_origal = nn.Conv2d(3, num_feat, 1, 1, 0)

        self.pixel_shuffle = nn.PixelShuffle(2)
        self.CSAM_module = CSAM_Module()
        self.deform_align = SecondOrderDeformableAlignment_01(
                    num_feat,
                    num_feat,
                    3,
                    padding=1,
                    deform_groups=2,  #  16
                    max_residue_magnitude=10)

        # activation functions
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        # residual network
        self.in_conv = nn.Sequential(nn.Conv2d(3, num_feat, 3, padding=1), nn.ReLU(inplace=True))
        hid_conv_lst = []
        for _ in range(8 - 2):
            hid_conv_lst += [nn.Conv2d(num_feat, num_feat, 3, padding=1),nn.ReLU(inplace=True)]
        self.hid_conv = nn.Sequential(*hid_conv_lst)
        self.out_conv = nn.Conv2d(num_feat, 3, 3, padding=1)

        self.FFP_conv = nn.Conv2d(num_feat, num_feat, 3, padding=1)
        self.FFP_conv2 = nn.Conv2d(2*num_feat, num_feat, 3, padding=1)

        # define head module
        modules_head = [nn.Conv2d(3, num_feat, 3 ,1, 1),
                        nn.ReLU(True),
                        nn.Conv2d(num_feat, num_feat, 3, 1, 1)]
        self.head = nn.Sequential(*modules_head)

        # spatial mask
        self.spa_mask = nn.Sequential(
            nn.Conv2d(3, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, 64, 3, 2, 1, output_padding=1),
        )
        self.spa_mask_1 = nn.Sequential(
            nn.Conv2d(num_feat, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.AvgPool2d(2),
            nn.Conv2d(num_feat//4, num_feat//4, 3, 1, 1),
            nn.ReLU(True),
            nn.ConvTranspose2d(num_feat // 4, num_feat, 3, 2, 1, output_padding=1),
        )
        self.tau = 1

        self.SELayer = SELayer(num_feat)
        self.eca_layer = eca_layer(num_feat)

    def pad_spatial(self, x):
        """ Apply padding spatially.

        Since the PCD module in EDVR requires that the resolution is a multiple
        of 4, we apply padding to the input LR images if their resolution is
        not divisible by 4.

        Args:
            x (Tensor): Input LR sequence with shape (n, t, c, h, w).
        Returns:
            Tensor: Padded LR sequence with shape (n, t, c, h_pad, w_pad).
        """
        n, t, c, h, w = x.size()

        pad_h = (4 - h % 4) % 4
        pad_w = (4 - w % 4) % 4

        # padding
        x = x.view(-1, c, h, w)
        x = F.pad(x, [0, pad_w, 0, pad_h], mode='reflect')

        return x.view(n, t, c, h + pad_h, w + pad_w)

    def get_flow(self, x):
        b, n, c, h, w = x.size()

        x_1 = x[:, :-1, :, :, :].reshape(-1, c, h, w)
        x_2 = x[:, 1:, :, :, :].reshape(-1, c, h, w)

        flows_backward = self.spynet(x_1, x_2).view(b, n - 1, 2, h, w)
        flows_forward = self.spynet(x_2, x_1).view(b, n - 1, 2, h, w)

        return flows_forward, flows_backward

    def gumbel_softmax(self, x, dim, tau):
        gumbels = torch.rand_like(x)
        while bool((gumbels == 0).sum() > 0):
            gumbels = torch.rand_like(x)

        gumbels = -(-gumbels.log()).log()
        gumbels = (x + gumbels) / tau
        x = gumbels.softmax(dim)

        return x
    
    def get_keyframe_feature(self, x, keyframe_idx):
        if self.temporal_padding == 2:
            x = [x[:, [4, 3]], x, x[:, [-4, -5]]]
        elif self.temporal_padding == 3:
            x = [x[:, [6, 5, 4]], x, x[:, [-5, -6, -7]]]
        x = torch.cat(x, dim=1)

        num_frames = 2 * self.temporal_padding + 1
        feats_keyframe = {}
        for i in keyframe_idx:
            # print("x[:, i:i + num_frames].contiguous()",x[:, i:i + num_frames].shape)  # e([2, 7, 3, 128, 128])
            feats_keyframe[i] = self.edvr(x[:, i:i + num_frames].contiguous())
        return feats_keyframe

    def FlowDeformableAlignment(self, feats, flow):
        """Propagate the latent features throughout the sequence.
        Args:
            feats dict(list[tensor]): Features from previous branches. Each
                component is a list of tensors with shape (n, c, h, w).
            flows (tensor): Optical flows with shape (n, t - 1, 2, h, w).
            module_name (str): The name of the propgation branches. Can either
                be 'backward_1', 'forward_1', 'backward_2', 'forward_2'.
        Return:
            dict(list[tensor]): A dictionary containing all the propgated
                features. Each key in the dictionary corresponds to a
                propagation branch, which is represented by a list of tensors.
        """
        nf, _, hf, wf = feats.shape
        n, t, h, w = flow.shape

        feat_prop = flow.new_zeros(n, 64, h, w)
        # print("[feat_prop 0 ]",feat_prop.shape)   #  [2, 64, 128, 128]
        feat_current = feats
        feat_current = feat_current.cuda()
        feat_prop = feat_prop.cuda()
        flow = flow.cuda()
        # print("cuda feat_current",feat_current.device)

        # second-order deformable alignment
        if self.is_with_alignment:
            # print("feat_prop feat_current",feat_prop.shape)
            # print("flow ",flow.shape)

            flow_n1 = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))  #  flow(0, 2, 3, 1)
            flow_n1 = flow_n1.cuda()
            # print("[flow_n1 0 ]",flow_n1.shape)   #  [4, 64, 128, 128]
            torch.cuda.empty_cache()
            cond = flow_warp(feat_current, flow.permute(0, 2, 3, 1))
            cond = cond.cuda()
            # print("[cond 0 ]",cond.shape)   #  ([2, 64, 128, 128])

            # flow-guided deformable convolution
            cond = torch.cat([cond, feat_current, flow_n1], dim=1)
            cond = cond.cuda()
            cond = self.conv_trans(cond)

            feat_prop = torch.cat([feat_prop, feats], dim=1)
            # feat_prop = self.conv_fetr(feat_prop)
            # print("[feats]",feats.shape)    #  ([2, 64, 128, 128])
            # print("[cond 1]",cond.shape)    #  ([2, 192, 128, 128])
            # print("[feat_prop]",feat_prop.shape)   #  [4, 128, 128, 128])
            torch.cuda.empty_cache()
            feat_prop = self.deform_align(feat_current, cond, flow)  # .cuda()  feat_prop
            feat_prop = feat_prop.cuda()
            torch.cuda.empty_cache()
            # print("[feat_prop]",feat_prop.shape)  #  ([4, 128, 128, 128])

        return feat_prop

    def forward(self, x):
        b, n, c, h_input, w_input = x.size()
        # h_input = h
        # w_input = w
        # x0 = x
        x = F.interpolate(x, size=(c, self.scale*h_input, self.scale*w_input), mode='trilinear', align_corners=False)
        # x = self.pad_spatial(x)
        b, n, c, h, w = x.shape 

        keyframe_idx = list(range(0, n, self.keyframe_stride))
        if keyframe_idx[-1] != n - 1:
            keyframe_idx.append(n - 1)  # last frame is a keyframe

        # compute flow and keyframe features
        flows_forward, flows_backward = self.get_flow(x)
        # feats_keyframe = self.get_keyframe_feature(x, keyframe_idx)

        # backward branch
        out_l = []
        out_fw = []
        out_sm = []
        feat_prop = x.new_zeros(b, self.num_feat, h, w)
        flow = flows_backward.new_zeros(b, 2, h, w)
        spa_mask = flows_backward.new_zeros(b, 3, h, w)
        for i in range(n - 1, -1, -1):
            x_i = x[:, i, :, :, :]
            if i < n - 1:
                flow = flows_backward[:, i, :, :, :]
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
            if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 backward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # spa_mask = spa_mask.view(b, n, -1, h, w)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.backward_fusion(feat_prop)
            feat_prop = torch.cat([x_i, feat_prop], dim=1)
            feat_prop = self.backward_trunk(feat_prop)
            out_l.insert(0, feat_prop)
            out_fw.insert(0, flow)
            out_sm.insert(0, spa_mask)
            
        # forward branch
        feat_prop = torch.zeros_like(feat_prop)
        flow = torch.zeros_like(flow)
        spa_mask = torch.zeros_like(spa_mask)
        for i in range(0, n):
            x_i = x[:, i, :, :, :]
            if i > 0:
                flow = flows_forward[:, i - 1, :, :, :]
                feat_prop = self.FlowDeformableAlignment(feat_prop, flow)
                # feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1))
            if i in keyframe_idx:
                # x_mk = x_i.view(-1, c, h, w)  # self.head(x.view(-1, c, h, w))
                # print("[x_mk]",x_mk.shape)   # ([2, 3, 128, 128])
                # spa_mask = self.spa_mask(x_mk)
                # print("[spa_mask 1 forward]",i)   #  [28, 3, 128, 128])
                # spa_mask = self.gumbel_softmax(spa_mask, 1, self.tau)
                # feat_prop = torch.cat([feat_prop,  feats_keyframe[i]], dim=1)
                feat_prop = self.forward_fusion(feat_prop)
            
            # flow_backprop = flow_warp(x_i, out_fw[i].permute(0, 2, 3, 1))
            # flow_foreprop = flow_warp(x_i, flow.permute(0, 2, 3, 1))
            x_diff = self.FFP_conv(self.conv_origal(x_i) - out_l[i])
            x_combine = torch.cat([self.conv_origal(x_i), x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer  SELayer
            x_back = self.conv_origal(x_i) + x_diff 
            # x_back = self.flow_trunk(x_back)

            x_diff = self.FFP_conv(x_back - feat_prop)
            x_combine = torch.cat([x_back, x_diff], dim=1)
            x_diff = self.eca_layer(self.FFP_conv2(x_combine))   #  eca_layer
            x_temporal = x_back + x_diff 
            flow_prop = self.flow_trunk(x_temporal)  #  joint optical flow fore - back
            # flow_prop = torch.cat([x_i, flow_prop], dim=1)  # 4 + 64
            spm_prop = self.spa_mask_1(flow_prop)
            spm_prop = self.gumbel_softmax(spm_prop, 1, self.tau)

            spam_prop = torch.cat([x_temporal, spm_prop], dim=1)  #  x_temporal
            spam_prop = self.spam_trunk(spam_prop) 

            # spam_prop = torch.cat([x_i, out_sm[i], spa_mask], dim=1)
            # spam_prop = self.spam_trunk(spam_prop)  
            feat_prop = torch.cat([x_i, flow_prop, spam_prop ], dim=1)   #  feat_prop

            # feat_prop = torch.cat([x_i, out_l[i], flow_prop, feat_prop ], dim=1)   #  feat_prop
            feat_prop = self.forward_trunk(feat_prop)
            # feat_prop = torch.cat([x_i, out_l[i], flow_prop, spam_prop, feat_prop], dim=1)
            # feat_prop = self.forward_trunk(feat_prop)

            # upsample
            # out = self.lrelu(self.pixel_shuffle(self.upconv1(feat_prop)))
            # out = self.lrelu(self.pixel_shuffle(self.upconv2(out)))
            # out = self.conv_last(out)

            out = self.lrelu(self.upconv1(feat_prop))
            out = self.conv_last(out)
          
            out_l[i] = out + x_i
        finout = torch.stack(out_l, dim=1)[..., :4 * h_input, :4 * w_input]


        return finout






class SecondOrderDeformableAlignment_01(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(SecondOrderDeformableAlignment_01, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.conv_offset_2 = nn.Sequential(
            nn.Conv2d(self.out_channels+4 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )


        self.conv_mask = nn.Sequential(
            nn.Conv2d(2*self.out_channels , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 9 * self.deform_groups, 3, 1, 1),
        )

        self.conv_changeto_flow = nn.Sequential(
            nn.Conv2d(self.out_channels//2 + self.out_channels//16 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 2, 3, 1, 1),
        )


        self.conv_bisoff = nn.Sequential(
            nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 18 * self.deform_groups, 3, 1, 1),
        )

        self.fc = nn.Sequential(
            nn.Linear(144, 144 , bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(144 , 144, bias=False),
            nn.ReLU(inplace=True),
        )
        self.SELayer = SELayer(9 * self.deform_groups)

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # offset = torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))

        # print('[offset]',offset.shape)  # [4, 144, 128, 128]
        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        all_off = torch.cat([extra_feat, x], dim=1)
        # print('[x]',x.shape)
        # print('[all_off]',all_off.shape)
        extra_offset = self.max_residue_magnitude * self.conv_bisoff(all_off)
        
        # print('[offset]',offset.shape)  #  [2, 288, 64, 64]
        # print('[flow_1]',flow_1.shape)  #  [2, 2, 64, 64]
        offset_1 = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  + extra_offset   #   

        offset_1_flow = self.conv_changeto_flow(offset_1)
        # print('[extra_feat]',extra_feat.shape) # 
        # print('[offset_1_flow]',offset_1_flow.shape)
        # print('[flow_1]',flow_1.shape)
        extra_feat_2 = flow_warp(extra_feat, offset_1_flow.permute(0, 2, 3, 1))
        extra_feat_2 = torch.cat([extra_feat_2, flow_1], dim=1)  
        # print('[extra_feat_2]',extra_feat_2.shape)
        out_2 = self.conv_offset_2(extra_feat_2) 
        o1_2, o2_2 , mask_2 = torch.chunk(out_2, 3, dim=1)
        offset_2 = self.max_residue_magnitude * torch.tanh(torch.cat((o1_2, o2_2), dim=1))  
        offset_2 = offset_1 + offset_2 + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset

        # mask   mask 
        # x_feat = self.conv_mask(x)
        # print('[mask]', mask.shape)
        # mask = mask + x_feat
        # mask = torch.cat([extra_feat, flow_1], dim=1) 
        mask = self.SELayer(mask_2)  # + mask_2
        mask = torch.sigmoid(mask)  #  


        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset_2, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT







class EDVRFeatureExtractor(nn.Module):

    def __init__(self, num_input_frame, num_feat, load_path):

        super(EDVRFeatureExtractor, self).__init__()

        self.center_frame_idx = num_input_frame // 2

        # extrat pyramid features
        self.conv_first = nn.Conv2d(3, num_feat, 3, 1, 1)
        self.feature_extraction = make_layer(ResidualBlockNoBN, 5, num_feat=64)
        self.conv_l2_1 = nn.Conv2d(num_feat, num_feat, 3, 2, 1)
        self.conv_l2_2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)
        self.conv_l3_1 = nn.Conv2d(num_feat, num_feat, 3, 2, 1)
        self.conv_l3_2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)

        # pcd and tsa module
        self.pcd_align = PCDAlignment(num_feat=num_feat, deformable_groups=8)
        self.fusion = TSAFusion(num_feat=num_feat, num_frame=num_input_frame, center_frame_idx=self.center_frame_idx)

        # activation function
        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)

        if load_path:
            self.load_state_dict(torch.load(load_path, map_location=lambda storage, loc: storage)['params'])

    def forward(self, x):
        b, n, c, h, w = x.size()

        # extract features for each frame
        # L1
        feat_l1 = self.lrelu(self.conv_first(x.view(-1, c, h, w)))
        feat_l1 = self.feature_extraction(feat_l1)
        # L2
        feat_l2 = self.lrelu(self.conv_l2_1(feat_l1))
        feat_l2 = self.lrelu(self.conv_l2_2(feat_l2))
        # L3
        feat_l3 = self.lrelu(self.conv_l3_1(feat_l2))
        feat_l3 = self.lrelu(self.conv_l3_2(feat_l3))

        feat_l1 = feat_l1.view(b, n, -1, h, w)
        feat_l2 = feat_l2.view(b, n, -1, h // 2, w // 2)
        feat_l3 = feat_l3.view(b, n, -1, h // 4, w // 4)

        # PCD alignment
        ref_feat_l = [  # reference feature list
            feat_l1[:, self.center_frame_idx, :, :, :].clone(), feat_l2[:, self.center_frame_idx, :, :, :].clone(),
            feat_l3[:, self.center_frame_idx, :, :, :].clone()
        ]
        aligned_feat = []
        for i in range(n):
            nbr_feat_l = [  # neighboring feature list
                feat_l1[:, i, :, :, :].clone(), feat_l2[:, i, :, :, :].clone(), feat_l3[:, i, :, :, :].clone()
            ]
            aligned_feat.append(self.pcd_align(nbr_feat_l, ref_feat_l))
        aligned_feat = torch.stack(aligned_feat, dim=1)  # (b, t, c, h, w)

        # TSA fusion
        return self.fusion(aligned_feat)


class SecondOrderDeformableAlignment(ModulatedDeformConv2d):
    """Second-order deformable alignment module.

    Args:
        in_channels (int): Same as nn.Conv2d.
        out_channels (int): Same as nn.Conv2d.
        kernel_size (int or tuple[int]): Same as nn.Conv2d.
        stride (int or tuple[int]): Same as nn.Conv2d.
        padding (int or tuple[int]): Same as nn.Conv2d.
        dilation (int or tuple[int]): Same as nn.Conv2d.
        groups (int): Same as nn.Conv2d.
        bias (bool or str): If specified as `auto`, it will be decided by the
            norm_cfg. Bias will be set as True if norm_cfg is None, otherwise
            False.
        max_residue_magnitude (int): The maximum magnitude of the offset
            residue (Eq. 6 in paper). Default: 10.

    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(SecondOrderDeformableAlignment, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        # print('[x]',x.shape)  # ([2, 128, 128, 128])
        # print('[extra_feat]',extra_feat.shape)  #  [2, 192, 128, 128])
        # print('[flow_1]',flow_1.shape)  #  ([2, 2, 128, 128])

        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        # print('[extra_feat]',extra_feat.shape)  # [4, 196, 128, 128]
        torch.cuda.empty_cache()
        # extra_feat=extra_feat.to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))
        out = self.conv_offset(extra_feat)   # 
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # print('[o1]',o1.shape)  #  [4, 72, 128, 128]
        # print('[o2]',o2.shape)  #  [4, 72, 128, 128]

        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # print('[offset]',offset.shape)  # [4, 144, 128, 128]
        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        offset = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)   #   
        offset = offset.contiguous()
        # print('[offset 1]',offset.shape)  # [4, 144, 128, 128]k

        # mask   mask 
        mask = torch.sigmoid(mask)  #  
        mask = mask.contiguous()
        # print('[mask]',mask.shape)   # ([4, 144, 128, 128])
        # print('[x]',x.shape)  #  ([4, 128, 128, 128])
        # print('[offset]',offset.shape)  #  ([4, 144, 128, 128])
        # print('[mask]',mask.shape)  #  ([4, 72, 128, 128])
        # x = x[:,:64,:,:].contiguous()
        # offset = offset[:,21,:,:].contiguous()  #   offset  mask mask
        # mask = mask[:,:36,:,:].contiguous()
        
        x = x.contiguous()
        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)  # .contiguous()
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT




class SecondOrderDeformableAlignment02(ModulatedDeformConv2d):
    """Second-order deformable alignment module.

    Args:
        in_channels (int): Same as nn.Conv2d.
        out_channels (int): Same as nn.Conv2d.
        kernel_size (int or tuple[int]): Same as nn.Conv2d.
        stride (int or tuple[int]): Same as nn.Conv2d.
        padding (int or tuple[int]): Same as nn.Conv2d.
        dilation (int or tuple[int]): Same as nn.Conv2d.
        groups (int): Same as nn.Conv2d.
        bias (bool or str): If specified as `auto`, it will be decided by the
            norm_cfg. Bias will be set as True if norm_cfg is None, otherwise
            False.
        max_residue_magnitude (int): The maximum magnitude of the offset
            residue (Eq. 6 in paper). Default: 10.

    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(SecondOrderDeformableAlignment, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            # nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        # print('[x]',x.shape)  # ([2, 128, 128, 128])
        # print('[extra_feat]',extra_feat.shape)  #  [2, 192, 128, 128])
        # print('[flow_1]',flow_1.shape)  #  ([2, 2, 128, 128])

        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        # print('[extra_feat]',extra_feat.shape)  # [4, 196, 128, 128]
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # print('[o1]',o1.shape)  #  [4, 72, 128, 128]
        # print('[o2]',o2.shape)  #  [4, 72, 128, 128]

        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # print('[offset]',offset.shape)  # [4, 144, 128, 128]
        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        offset = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)   #   
        # print('[offset 1]',offset.shape)  # [4, 144, 128, 128]k

        # mask   mask 
        mask = torch.sigmoid(mask)  #  
        # print('[mask]',mask.shape)   # ([4, 144, 128, 128])
        # print('[x]',x.shape)  #  ([4, 128, 128, 128])
        # print('[offset]',offset.shape)  #  ([4, 144, 128, 128])
        # print('[mask]',mask.shape)  #  ([4, 72, 128, 128])
        # x = x[:,:64,:,:].contiguous()
        # offset = offset[:,21,:,:].contiguous()  #   offset  mask mask
        # mask = mask[:,:36,:,:].contiguous()

        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT






class SecondOrderDeformableAlignment01(ModulatedDeformConv2d):

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(SecondOrderDeformableAlignment01, self).__init__(*args, **kwargs)

        # self.conv_mask = nn.Conv2d(64, 27 * self.deform_groups//2, 3, 1, 1)
        self.conv_mask = nn.Sequential(
            nn.Conv2d(64 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups//2, 3, 1, 1),)
        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        # print('[x]',x.shape)  # ([2, 128, 128, 128])
        # print('[extra_feat]',extra_feat.shape)  #  [2, 192, 128, 128])
        # print('[flow_1]',flow_1.shape)  #  ([2, 2, 128, 128])

        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset flow
        # extra_feat = flow_warp(extra_feat, flow_1.permute(0, 2, 3, 1))
        # print('[extra_feat]',extra_feat.shape)  # [4, 196, 128, 128]
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        # o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # print('[o1]',o1.shape)  #  [4, 72, 128, 128]
        # print('[o2]',o2.shape)  #  [4, 72, 128, 128]

        # offset
        offset = self.max_residue_magnitude * out     

        # offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # print('[offset]',offset.shape)  # [4, 144, 128, 128]
        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        offset = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)   #   
        # print('[offset 1]',offset.shape)  # [4, 144, 128, 128]k

        # mask   mask 
        mask = self.conv_mask(x)
        mask = torch.sigmoid(mask)  #  
        # print('[mask]',mask.shape)   # ([4, 144, 128, 128])
        # print('[x]',x.shape)  #  ([4, 128, 128, 128])
        # print('[offset]',offset.shape)  #  ([4, 144, 128, 128])
        # print('[mask]',mask.shape)  #  ([4, 72, 128, 128])
        # x = x[:,:64,:,:].contiguous()
        # offset = offset[:,21,:,:].contiguous()  #   offset  mask mask
        # mask = mask[:,:36,:,:].contiguous()

        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT



class AFF(nn.Module):
    def __init__(self, in_channel, out_channel):
        super(AFF, self).__init__()
        self.conv = nn.Sequential(
            BasicConv(in_channel, out_channel, kernel_size=1, stride=1, relu=True),
            BasicConv(out_channel, out_channel, kernel_size=3, stride=1, relu=False)
        )

    def forward(self, x1, x2, x3, x4):
        x = torch.cat([x1, x2, x3, x4], dim=1)
        return self.conv(x)


class BasicConv(nn.Module):
    def __init__(self, in_channel, out_channel, kernel_size, stride, bias=True, norm=False, relu=True, transpose=False):
        super(BasicConv, self).__init__()
        if bias and norm:
            bias = False

        padding = kernel_size // 2
        layers = list()
        if transpose:
            padding = kernel_size // 2 -1
            layers.append(nn.ConvTranspose2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))
        else:
            layers.append(
                nn.Conv2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))
        if norm:
            layers.append(nn.BatchNorm2d(out_channel))
        if relu:
            layers.append(nn.ReLU(inplace=True))
        self.main = nn.Sequential(*layers)

    def forward(self, x):
        return self.main(x)


class CSAM_Module(nn.Module):
    """ Channel-Spatial attention module"""
    def __init__(self):
        super(CSAM_Module, self).__init__()
        # self.chanel_in = in_dim
        self.conv = nn.Conv3d(7, 1, 3, 1, 1)
        self.conv_x = nn.Conv2d(128, 3, 3, 1, 1)
        self.gamma = nn.Parameter(torch.zeros(1))
        self.softmax  = nn.Softmax(dim=-1)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x1, x2):
        """
            inputs :
                x : input feature maps( B  N  C  H  W)
            returns :
                out : attention value + input feature
                attention: B X N X N
        """
        # print('[CSAM_Module before shape]',x2.shape)
        # x = x2.permute(0,2,3,1)
        x = x2  # .unsqueeze(1)
        print('[CSAM_Module before shape 1]',x.shape)

        m_batchsize, N, C, height, width = x.size()
        # print('[CSAM_Module shape]',x.shape)
        # out = x.squeeze(1)
        out = x1
        out = self.sigmoid(self.conv(out))
        
        proj_query = x.contiguous().view(m_batchsize, N, -1)
        proj_key = x.contiguous().view(m_batchsize, N, -1).permute(0, 2, 1)
        energy = torch.bmm(proj_query, proj_key)
        energy_new = torch.max(energy, -1, keepdim=True)[0].expand_as(energy)-energy
        attention = self.softmax(energy_new)
        proj_value = x.contiguous().view(m_batchsize, N, -1)

        out = torch.bmm(attention, proj_value)
        out = out.contiguous().view(m_batchsize, N, C, height, width)

        out = self.gamma*out   #  
        out = out.contiguous().view(m_batchsize,N, -1, height, width)
        # print('[CSAM_Module x1 shape]',x1.shape)   #  [2, 3, 128, 128]
        # print('[CSAM_Module out shape]',out.shape)  #  [2, 128, 128, 128]
        # x = x * out + x
        # xo = self.conv_x(x2 * out) + x1
        print('[CSAM_Module x1 shape]',x1.shape)  #  ([60, 1, 2, 128, 128])
        print('[CSAM_Module out shape]',out.shape)  #  ([4, 15, 3, 128, 128])
        # print('[CSAM_Module after shape]',xo.shape)
        xo = x1 * out + x1

        # xo = xo.permute(0,3,1,2)
        # print('[CSAM_Module after shape]',xo.shape)

        return xo




class SecondOrderDeformableAlignment_02(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(SecondOrderDeformableAlignment_02, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        # self.conv_offset_2 = nn.Sequential(
        #     nn.Conv2d(self.out_channels+4 , self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        # )


        # self.conv_mask = nn.Sequential(
        #     nn.Conv2d(2*self.out_channels , self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     # nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     # nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     # nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, 9 * self.deform_groups, 3, 1, 1),
        # )

        # self.conv_changeto_flow = nn.Sequential(
        #     nn.Conv2d(2*self.out_channels + self.out_channels//4 , self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, 2, 3, 1, 1),
        # )


        # self.conv_bisoff = nn.Sequential(
        #     nn.Conv2d(3*self.out_channels+2 , self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
        #     nn.LeakyReLU(negative_slope=0.1, inplace=True),
        #     nn.Conv2d(self.out_channels, 18 * self.deform_groups, 3, 1, 1),
        # )

        # self.fc = nn.Sequential(
        #     nn.Linear(144, 144 , bias=False),
        #     nn.ReLU(inplace=True),
        #     nn.Linear(144 , 144, bias=False),
        #     nn.ReLU(inplace=True),
        # )
        # self.SELayer = SELayer(9 * self.deform_groups)

        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        # extra_feat = flow_warp(extra_feat, flow_1)
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        # print('[out]',out.shape)  # [4, 216, 128, 128]  ([4, 108, 128, 128])
        torch.cuda.empty_cache()
        # o1, mask = torch.chunk(out, 2, dim=1)  # tensor mask 
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        # offset = torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))

        # print('[offset]',offset.shape)  # [4, 144, 128, 128]
        torch.cuda.empty_cache()
        torch.cuda.empty_cache()
        # all_off = torch.cat([extra_feat, x], dim=1)
        # # print('[x]',x.shape)
        # # print('[all_off]',all_off.shape)
        # extra_offset = self.max_residue_magnitude * self.conv_bisoff(all_off)
        
        # # print('[offset]',offset.shape)  #  [2, 288, 64, 64]
        # # print('[flow_1]',flow_1.shape)  #  [2, 2, 64, 64]
        # offset_1 = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  + extra_offset   #   

        # offset_1_flow = self.conv_changeto_flow(offset_1)
        # # print('[extra_feat]',extra_feat.shape) # 
        # # print('[offset_1_flow]',offset_1_flow.shape)
        # # print('[flow_1]',flow_1.shape)
        # extra_feat_2 = flow_warp(extra_feat, offset_1_flow.permute(0, 2, 3, 1))
        # extra_feat_2 = torch.cat([extra_feat_2, flow_1], dim=1)  
        # # print('[extra_feat_2]',extra_feat_2.shape)
        # out_2 = self.conv_offset_2(extra_feat_2) 
        # o1_2, o2_2 , mask_2 = torch.chunk(out_2, 3, dim=1)
        # offset_2 = self.max_residue_magnitude * torch.tanh(torch.cat((o1_2, o2_2), dim=1))  
        # offset_2 = offset_1 + offset_2 + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)  # + extra_offset

        # mask   mask 
        # x_feat = self.conv_mask(x)
        # print('[mask]', mask.shape)
        # mask = mask + x_feat
        # mask = torch.cat([extra_feat, flow_1], dim=1) 
        # mask = self.SELayer(mask)  # + mask_2
        mask = torch.sigmoid(mask)  #  


        torch.cuda.empty_cache()
        OUT = modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print("[OUT]",OUT.shape)   # ([1, 64, 128, 128])

        return OUT





class CasDeformableAlignment(ModulatedDeformConv2d):  
    """Second-order deformable alignment module.
    """

    def __init__(self, *args, **kwargs):
        self.max_residue_magnitude = kwargs.pop('max_residue_magnitude', 10)

        super(CasDeformableAlignment, self).__init__(*args, **kwargs)

        self.conv_offset = nn.Sequential(
            nn.Conv2d(self.out_channels+2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )

        self.conv_offset_2 = nn.Sequential(
            nn.Conv2d(self.out_channels*2 + 2 , self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1),
            nn.LeakyReLU(negative_slope=0.1, inplace=True),
            nn.Conv2d(self.out_channels, 27 * self.deform_groups, 3, 1, 1),
        )


        self.init_offset()

    def init_offset(self):
        constant_init(self.conv_offset[-1], val=0, bias=0)

    def forward(self, x, extra_feat, flow_1):
        extra_feat = torch.cat([extra_feat, flow_1], dim=1)   #  conncat  offset 
        torch.cuda.empty_cache()
        out = self.conv_offset(extra_feat)   #    
        torch.cuda.empty_cache()
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     #torch.tanh(torch.cat((o1, o2), dim=1))
        offset = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)   #   

        torch.cuda.empty_cache()
        torch.cuda.empty_cache()

        mask = torch.sigmoid(mask) 

        torch.cuda.empty_cache()
        OUT_1 = modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print('[OUT_1]',OUT_1.shape)
        extra_feat = torch.cat([OUT_1, extra_feat], dim=1)
        out = self.conv_offset_2(extra_feat)   
        torch.cuda.empty_cache()
        o1, o2 , mask = torch.chunk(out, 3, dim=1)
        # offset
        offset = self.max_residue_magnitude * torch.tanh(torch.cat((o1, o2), dim=1))     
        offset = offset + flow_1.flip(1).repeat(1,offset.size(1) // 2, 1, 1)   

        torch.cuda.empty_cache()
        torch.cuda.empty_cache()

        mask = torch.sigmoid(mask) 
        OUT = modulated_deform_conv2d(x, offset, mask, self.weight, self.bias,
                                       self.stride, self.padding,
                                       self.dilation, self.groups,
                                       self.deform_groups)
        # print('[OUT]',OUT.shape)
        return OUT







class Backward_warp(nn.Module):

    def __init__(self):
        super(Backward_warp,self).__init__()

 
    def _meshgrid(self,height,width):

        y_t = torch.linspace(0,height - 1, height).reshape(height,1) * torch.ones(1,width)
        x_t = torch.ones(height,1) * torch.linspace(0, width - 1, width).reshape(1,width)

        x_t_flat = x_t.reshape(1,1,height,width)
        y_t_flat = y_t.reshape(1,1,height,width)

        grid = torch.cat((x_t_flat,y_t_flat),1)

        return grid


    def _interpolate(self,img , x, y , out_height, out_width):

        num_batch,height,width,num_channel = img.size()
        height_f = float(height)
        width_f = float(width)

        x = torch.clamp(x,0,width - 1)
        y = torch.clamp(y,0,height - 1)

        x0_f = x.floor().cuda()
        y0_f = y.floor().cuda()
        x1_f = x0_f + 1.0
        y1_f = y0_f + 1.0

        x0 = torch.tensor(x0_f, dtype = torch.int64)
        y0 = torch.tensor(y0_f, dtype = torch.int64)
        x1 = torch.tensor(torch.clamp(x1_f, 0, width_f -1), dtype = torch.int64)
        y1 = torch.tensor(torch.clamp(y1_f, 0, height_f -1), dtype = torch.int64)
 
        dim1 = width * height
        dim2 = width
        base = torch.tensor((torch.arange(num_batch) * dim1),dtype = torch.int64).cuda()
        base = base.reshape(num_batch,1).repeat(1,out_height * out_width).view(-1).cuda()

        base_y0 = base + y0 * dim2
        base_y1 = base + y1 * dim2

        idx_a = base_y0 + x0
        idx_b = base_y1 + x0
        idx_c = base_y0 + x1
        idx_d = base_y1 + x1

        img_flat = img.reshape(-1,num_channel)

        Ia = img_flat[idx_a]
        Ib = img_flat[idx_b]
        Ic = img_flat[idx_c]
        Id = img_flat[idx_d]

        wa = ((x1_f-x) * (y1_f-y)).reshape(-1,1)
        wb = ((x1_f-x) * (y-y0_f)).reshape(-1,1)
        wc = ((x-x0_f) * (y1_f-y)).reshape(-1,1)
        wd = ((x-x0_f) * (y-y0_f)).reshape(-1,1)
        output = wa * Ia + wb * Ib + wc * Ic + wd *Id

        return output


    def _transform_flow(self,flow,input,downsample_factor):

        num_batch,num_channel,height,width = input.size()

        out_height = height
        out_width = width
        grid = self._meshgrid(height, width)
        if num_batch > 1:
            grid = grid.repeat(num_batch,1,1,1)

        control_point = grid.cuda() + flow
        input_t = input.permute(0,2,3,1)

        x_s_flat = control_point[:,0,:,:].contiguous().view(-1)
        y_s_flat = control_point[:,1,:,:].contiguous().view(-1)

        input_transformed = self._interpolate(input_t,x_s_flat,y_s_flat,out_height,out_width)

        input_transformed = input_transformed.reshape(num_batch,out_height,out_width,num_channel)

        output = input_transformed.permute(0,3,1,2)

        return output

    def forward(self,input,flow,downsample_factor = 1):

        return self._transform_flow(flow,input, downsample_factor)





if __name__ == '__main__':
    with torch.no_grad():
        class ICMEVSRx4_FG_SPM_liteflow2_img_warp_our:
            def __init__(self):
                self.num_feat= 64
                self.num_block=10 # 10  # 30
                self.keyframe_stride=5
                self.temporal_padding= 3  # 3
                self.spynet_path='/share4/home/zqiang/BasicSR0906/experiments/pretrained_models/flownet/spynet/spynet_L-chairs_later.pth'
        from thop import profile
        # net = Net(ICMEVSRx4_FG_SPM_liteflow2_img_warp_our()).cuda()
        net = ICMEVSRx4_FG_SPM_liteflow2_img_warp_our().cuda()
        inputs = torch.rand((1, 3, 720//4, 1280//4)).cuda()
        macs, param = profile(net, (inputs,))
        print('MACs (G):', macs/1000/1000/1000)
        print('Param (M):', param/1000/1000)
        # MACs(G): 988.8344309759999
        # Param(M): 3.459563